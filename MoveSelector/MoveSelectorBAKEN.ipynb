{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/averyrair/ChessBAKEN/blob/kenny/MoveSelector/MoveSelectorBAKEN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "\n",
        "!pip install chess\n",
        "#!pip install stockfish\n",
        "#!apt install stockfish"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMHzza4EUkGk",
        "outputId": "17bfe93a-66ed-4837-bbb4-3927ee5c306d",
        "cellView": "form"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chess in /usr/local/lib/python3.11/dist-packages (1.11.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Directories\n",
        "\n",
        "from google.colab import drive\n",
        "# For this to work, you need to have the \"Chess Bot BAKEN\" project shared with\n",
        "# the SAME email you linked this Colab to, presumably your GitHub email address.\n",
        "drive.mount('/content/drive', force_remount=1)\n",
        "chess_dir = '/content/drive/Shareddrives/Chess Bot BAKEN'"
      ],
      "metadata": {
        "id": "dR6-7kOo5ybX",
        "outputId": "c9202977-9dfb-404d-f43e-799d01eca822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "U1gs1RsOT7Ha",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import Libraries\n",
        "\n",
        "import os\n",
        "import chess\n",
        "import chess.pgn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Custom Board Representation\n",
        "\n",
        "def customBoardRep(board):\n",
        "\n",
        "  return board.fen().split(\" \")[0]"
      ],
      "metadata": {
        "id": "VEEak8R7EdJ5",
        "cellView": "form"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import PGN and Export CSV\n",
        "\n",
        "import chess.pgn\n",
        "#if not os.path.exists(os.path.join(chess_dir, 'moveSelectorDataset.csv')):\n",
        "if 0:\n",
        "  pgn_dir = os.path.join(chess_dir, 'KingBase2019-pgn')\n",
        "  pgnFiles = [os.path.join(pgn_dir, f) for f in os.listdir(pgn_dir) if f.endswith('.pgn')]\n",
        "\n",
        "  # Read every PGN file in the directory.\n",
        "  iterator = 0\n",
        "  for pgnFile in pgnFiles:\n",
        "    print(pgnFile)\n",
        "    pgn = open(pgnFile)\n",
        "\n",
        "    # Prepare CSV to export dataset.\n",
        "    with open(os.path.join(chess_dir, 'moveSelectorDataset' + pgnFile[74:81] +'.csv'), 'w') as csvfile:\n",
        "      csvwriter = csv.writer(csvfile)\n",
        "      #csvwriter.writeheader(['Label', 'Input'])\n",
        "\n",
        "      # Read every game in the PGN file.\n",
        "      while True:\n",
        "        game = chess.pgn.read_game(pgn)\n",
        "        if game is None: break\n",
        "        iterator += 1\n",
        "        if iterator % 500 == 0:\n",
        "          print(iterator)\n",
        "          #break\n",
        "        board = game.board()\n",
        "\n",
        "        # New data point for every move in the game.\n",
        "        gameMoves = list(game.mainline_moves())\n",
        "        for i in range(len(gameMoves)-1):\n",
        "          board.push(gameMoves[i])\n",
        "          legalMoves = \"\"\n",
        "          for m in list(board.legal_moves):\n",
        "            legalMoves = legalMoves + str(m) + \" \"\n",
        "          legalMoves = legalMoves.removesuffix(\" \")\n",
        "          #print(gameMoves[i+1], legalMoves, customBoardRep(board))\n",
        "          csvwriter.writerow([gameMoves[i+1], customBoardRep(board), legalMoves])"
      ],
      "metadata": {
        "id": "h-0ocmM9PmZo",
        "cellView": "form"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Fully-Connected Neural Network\n",
        "\n",
        "class myFCN(nn.Module):\n",
        "  def __init__(self, inSize, hiddenSizes, outSize):\n",
        "    super().__init__()\n",
        "    self.inSize = inSize\n",
        "    self.hiddenSize = hiddenSizes\n",
        "    self.outSize = outSize\n",
        "\n",
        "    self.lin1 = nn.Linear(inSize, hiddenSizes[0])\n",
        "    self.lin2 = nn.Linear(hiddenSizes[0], hiddenSizes[1])\n",
        "    self.lin3 = nn.Linear(hiddenSizes[1], outSize)\n",
        "\n",
        "    self.bn1 = nn.BatchNorm1d(hiddenSizes[0])\n",
        "    self.bn2 = nn.BatchNorm1d(hiddenSizes[1])\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax(dim=0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.bn1(self.lin1(x)))\n",
        "    x = self.relu(self.bn2(self.lin2(x)))\n",
        "    x = self.softmax(self.lin3(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "_xIwaUL2Ef0n",
        "cellView": "form"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Fully-Connected Neural Network\n",
        "\n",
        "currentModelFile = 'MoveSelectorV1.4.pt'\n",
        "\n",
        "moveSelector = myFCN(inSize=2560, hiddenSizes=[2200, 2200], outSize=1792)\n",
        "if (os.path.exists(os.path.join(chess_dir, currentModelFile))):\n",
        "  moveSelector = torch.load(os.path.join(chess_dir, currentModelFile), weights_only=False)\n",
        "  moveSelector.eval()\n",
        "  print(\"Loaded Model: \" + currentModelFile)\n",
        "print(moveSelector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtwHkKzU-30B",
        "outputId": "a9febc2b-0890-4f64-95d1-3185198dfd5e",
        "cellView": "form"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Model: MoveSelectorV1.4.pt\n",
            "myFCN(\n",
            "  (lin1): Linear(in_features=2560, out_features=2200, bias=True)\n",
            "  (lin2): Linear(in_features=2200, out_features=2200, bias=True)\n",
            "  (lin3): Linear(in_features=2200, out_features=1792, bias=True)\n",
            "  (bn1): BatchNorm1d(2200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm1d(2200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Dataset\n",
        "\n",
        "class ChessDataset(Dataset):\n",
        "    def __init__(self, chessgame_file, chess_dir, transform=None, target_transform=None):\n",
        "        self.game_labels = pd.read_csv(chessgame_file)\n",
        "        self.chess_dir = chess_dir  # This is not used. Everything is in the chessgame file.\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.game_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.game_labels.iloc[idx, 0]\n",
        "        gameState = self.game_labels.iloc[idx, 1]\n",
        "        moves = self.game_labels.iloc[idx, 2]\n",
        "\n",
        "        return gameState, moves, label"
      ],
      "metadata": {
        "id": "gEJ_xS5Kc-PN",
        "cellView": "form"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Encode/Decode Functions\n",
        "\n",
        "# The number of possible pieces and square states (8*8*6*2)\n",
        "NUM_BOARD_NODES = 768\n",
        "# The number of possible moves from any square to any other\n",
        "NUM_MOVE_NODES = 1792\n",
        "\n",
        "\n",
        "# Determines whether any piece could ever move from one square to another\n",
        "# Note: pass in start and end coordinates as tuples containing two ints\n",
        "def canMove(start, end):\n",
        "    # check duplicate\n",
        "    if start[0] == end[0] and start[1] == end[1]:\n",
        "        return False\n",
        "\n",
        "    # check row or col\n",
        "    if start[0] == end[0] or start[1] == end[1]:\n",
        "        return True\n",
        "\n",
        "    # check diagonal\n",
        "    if abs(start[0]-end[0]) == abs(start[1]-end[1]):\n",
        "        return True\n",
        "\n",
        "    # check knight\n",
        "    knightCases = [(1, 2), (1, -2), (-1, 2), (-1, -2),\n",
        "                   (2, 1), (2, -1), (-2, 1), (-2, -1)]\n",
        "    for c in knightCases:\n",
        "        if start[0] + c[0] == end[0] and start[1] + c[1] == end[1]:\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "# Generate the mapping matrix (only needs to be done once)\n",
        "def getMappingMatrix():\n",
        "    moveMap = [[[[0 for l in range(8)] for k in range(\n",
        "        8)] for j in range(8)] for i in range(8)]\n",
        "    offset = 0\n",
        "    for i in range(8):\n",
        "        for j in range(8):\n",
        "            for k in range(8):\n",
        "                for l in range(8):\n",
        "                    if canMove((i, j), (k, l)):\n",
        "                        moveMap[i][j][k][l] = offset\n",
        "                        offset += 1\n",
        "    return moveMap\n",
        "\n",
        "# Encode a board position and legal moves into a binary array\n",
        "def encodeSelector(boardFEN, moves, moveMap):\n",
        "    # Encode board position\n",
        "    encodedBoard = [0 for _ in range(NUM_BOARD_NODES)]\n",
        "    rowsFEN = boardFEN.split('/')\n",
        "    for i in range(8):\n",
        "        col = 0\n",
        "        for j in range(len(rowsFEN[i])):\n",
        "            if rowsFEN[i][j].isdigit():\n",
        "                col += ord(rowsFEN[i][j])-48\n",
        "            else:\n",
        "                match rowsFEN[i][j]:\n",
        "                    case 'P':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (0*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'N':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (1*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'B':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (2*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'R':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (3*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'Q':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (4*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'K':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (5*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'p':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (0*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'n':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (1*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'b':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (2*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'r':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (3*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'q':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (4*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'k':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (5*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                col += 1\n",
        "\n",
        "    # Encode possible moves\n",
        "    encodedMoves = [0 for _ in range(NUM_MOVE_NODES)]\n",
        "    for m in moves.split(' '):\n",
        "        startCol = ord(str(m)[0])-97  # e.g. c -> 2\n",
        "        startRow = ord(str(m)[1])-49  # e.g. 8 -> 7\n",
        "        endCol = ord(str(m)[2])-97\n",
        "        endRow = ord(str(m)[3])-49\n",
        "        encodedMoves[(moveMap[startCol][startRow][endCol][endRow])] = 1\n",
        "\n",
        "    # Combine into single list\n",
        "    return encodedBoard + encodedMoves\n",
        "\n",
        "\n",
        "# Decode board position from a binary array of length 768\n",
        "def decodePosition(input):\n",
        "    # Create matrix of board\n",
        "    boardMatrix = [['.' for _ in range(8)] for _ in range(8)]\n",
        "\n",
        "    # Populate board\n",
        "    for i in range(len(input)):\n",
        "        if input[i] == 1:\n",
        "            piece = i % 12\n",
        "            # Piece: P = 0, R = 1, N = 2, B = 3, Q = 4, K = 5\n",
        "            # Color: W = 0, B = 1\n",
        "            pieceLabel = '.'\n",
        "            match piece:\n",
        "                case 0:\n",
        "                    pieceLabel = 'P'\n",
        "                case 1:\n",
        "                    pieceLabel = 'p'\n",
        "                case 2:\n",
        "                    pieceLabel = 'N'\n",
        "                case 3:\n",
        "                    pieceLabel = 'n'\n",
        "                case 4:\n",
        "                    pieceLabel = 'B'\n",
        "                case 5:\n",
        "                    pieceLabel = 'b'\n",
        "                case 6:\n",
        "                    pieceLabel = 'R'\n",
        "                case 7:\n",
        "                    pieceLabel = 'r'\n",
        "                case 8:\n",
        "                    pieceLabel = 'Q'\n",
        "                case 9:\n",
        "                    pieceLabel = 'q'\n",
        "                case 10:\n",
        "                    pieceLabel = 'K'\n",
        "                case 11:\n",
        "                    pieceLabel = 'k'\n",
        "            boardMatrix[int(i / (6*2)) % 8][int(i / (8*6*2))] = pieceLabel\n",
        "\n",
        "    # Convert to FEN notation\n",
        "    boardFEN = ''\n",
        "    for i in range(len(boardMatrix)):\n",
        "        empty = 0\n",
        "        for j in range(len(boardMatrix[i])):\n",
        "            if boardMatrix[i][j] == '.':\n",
        "                empty += 1\n",
        "            else:\n",
        "                if empty > 0:\n",
        "                    boardFEN += str(empty)\n",
        "                    empty = 0\n",
        "                boardFEN += boardMatrix[i][j]\n",
        "        if empty > 0:\n",
        "            boardFEN += str(empty)\n",
        "        if i < len(boardMatrix) - 1:\n",
        "            boardFEN += '/'\n",
        "\n",
        "    return chess.Board(boardFEN)\n",
        "\n",
        "\n",
        "# Decode moves from a binary array of length 1792\n",
        "# Returns a list of moves with start and end squares\n",
        "def decodeMoves(input, moveMap):\n",
        "    moves = []\n",
        "    for h in range(len(input)):\n",
        "        if input[h] > 0: # NOTE: may need to change this condition based on selector NN output\n",
        "            # Search moveMap to find the actual move squares\n",
        "            found = False\n",
        "            for i in range(8):\n",
        "                for j in range(8):\n",
        "                    for k in range(8):\n",
        "                        for l in range(8):\n",
        "                            if moveMap[i][j][k][l] == h:\n",
        "                                moves.append(chr(i+97) + chr(j+49) + chr(k+97) + chr(l+49))\n",
        "                                found = True\n",
        "                                break\n",
        "                        if found:\n",
        "                            break\n",
        "                    if found:\n",
        "                        break\n",
        "                if found:\n",
        "                    break\n",
        "    return moves\n",
        "\n",
        "def decodeLegalMoves(original, input, moveMap, threshold = 0):\n",
        "    indices = [i for i, x in enumerate(original) if x == 1]\n",
        "    moves = []\n",
        "    for h in indices:#range(len(input)):\n",
        "        if input[h] > threshold: # NOTE: may need to change this condition based on selector NN output\n",
        "            # Search moveMap to find the actual move squares\n",
        "            found = False\n",
        "            for i in range(8):\n",
        "                for j in range(8):\n",
        "                    for k in range(8):\n",
        "                        for l in range(8):\n",
        "                            if moveMap[i][j][k][l] == h:\n",
        "                                moves.append((chr(i+97) + chr(j+49) + chr(k+97) + chr(l+49), input[h].item()))\n",
        "                                found = True\n",
        "                                break\n",
        "                        if found:\n",
        "                            break\n",
        "                    if found:\n",
        "                        break\n",
        "                if found:\n",
        "                    break\n",
        "    return moves\n",
        "\n",
        "def moveLabel(moveMade, moveMap):\n",
        "    encodedMoves = [0 for _ in range(NUM_MOVE_NODES)]\n",
        "    startCol = ord(str(moveMade)[0])-97  # e.g. c -> 2\n",
        "    startRow = ord(str(moveMade)[1])-49  # e.g. 8 -> 7\n",
        "    endCol = ord(str(moveMade)[2])-97\n",
        "    endRow = ord(str(moveMade)[3])-49\n",
        "    encodedMoves[(moveMap[startCol][startRow][endCol][endRow])] = 1\n",
        "    return encodedMoves\n",
        "\n",
        "def getMoveLoss(modelOutput, expectedOutput, weighting = NUM_MOVE_NODES):\n",
        "    totalLoss = 0\n",
        "    for i in range(NUM_MOVE_NODES):\n",
        "        if expectedOutput[i] == 1:\n",
        "            # model should output value close to 1\n",
        "            totalLoss += abs(1 - modelOutput[i]) * weighting\n",
        "            pass\n",
        "        else:\n",
        "            # model should output value close to 0\n",
        "            totalLoss += abs(modelOutput[i])\n",
        "            pass\n",
        "    return totalLoss\n",
        "\n",
        "def getMoveLossV1(modelOutput, moveMade, moveMap, weighting = NUM_MOVE_NODES):\n",
        "    startCol = ord(str(moveMade)[0])-97  # e.g. c -> 2\n",
        "    startRow = ord(str(moveMade)[1])-49  # e.g. 8 -> 7\n",
        "    endCol = ord(str(moveMade)[2])-97\n",
        "    endRow = ord(str(moveMade)[3])-49\n",
        "    #totalLoss = torch.sum(modelOutput)\n",
        "    totalLoss = abs(1 - modelOutput[(moveMap[startCol][startRow][endCol][endRow])]) * weighting\n",
        "\n",
        "    return totalLoss\n",
        "\n",
        "def getMoveLossV2(modelOutput, moveMade, moveMap):\n",
        "    startCol = ord(str(moveMade)[0])-97  # e.g. c -> 2\n",
        "    startRow = ord(str(moveMade)[1])-49  # e.g. 8 -> 7\n",
        "    endCol = ord(str(moveMade)[2])-97\n",
        "    endRow = ord(str(moveMade)[3])-49\n",
        "\n",
        "    moveChance = modelOutput[moveMap[startCol][startRow][endCol][endRow]]\n",
        "    losses = [x for x in modelOutput if x >= moveChance]\n",
        "    # This just doesn't really work at all.\n",
        "    return torch.tensor(len(losses), dtype=torch.float, requires_grad=True)\n",
        "\n",
        "### TESTING ###\n",
        "\n",
        "# Test the encoder and decoder\n",
        "def testEncodeDecode():\n",
        "    # Encode board\n",
        "    moveMap = getMappingMatrix()\n",
        "    with open(os.path.join(chess_dir, 'Move Selector Dataset', 'moveSelectorDatasetD70-D99.csv'), 'r') as file:\n",
        "        data = list(csv.reader(file))\n",
        "    curr = data[0]\n",
        "    encoded = encodeSelector(curr[1], curr[2], moveMap)\n",
        "\n",
        "    # Decode board\n",
        "    decodedBoard = decodePosition(encoded[0:NUM_BOARD_NODES])\n",
        "    decodedMoves = decodeMoves(encoded[-NUM_MOVE_NODES:], moveMap)\n",
        "\n",
        "    # Compare original and decoded position/moves\n",
        "    print('Original position and legal moves: ')\n",
        "    print(chess.Board(curr[1]))\n",
        "    print(sorted(curr[2].split(' ')))\n",
        "    print('---------------')\n",
        "    print('Decoded position and legal moves: ')\n",
        "    print(decodedBoard)\n",
        "    print(decodedMoves)\n",
        "\n",
        "#testEncodeDecode()"
      ],
      "metadata": {
        "id": "rBWRuqgqqlOj",
        "cellView": "form"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train Model\n",
        "\n",
        "dataset = ChessDataset(chessgame_file=os.path.join(chess_dir, 'Move Selector Dataset/moveSelectorDatasetA00-A39.csv'), chess_dir=chess_dir)\n",
        "moveMap = getMappingMatrix()\n",
        "\n",
        "optim = torch.optim.SGD(moveSelector.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "epochs = 5\n",
        "batchSize = 128\n",
        "percentageOfDataset = 0.1\n",
        "\n",
        "print(\"Number of Positions Training On: \", int(len(dataset)*percentageOfDataset))\n",
        "print(\"Estimated Training Time: \", int(len(dataset)*percentageOfDataset*epochs/5000), \" minutes\")  #V1\n",
        "#print(\"Estimated Training Time: \", int(len(dataset)*percentageOfDataset*epochs/1000), \" minutes\")  #V2\n",
        "\n",
        "for e in range(epochs):\n",
        "  runningLoss = 0\n",
        "\n",
        "  # Number of batches\n",
        "  for b in range(int(len(dataset)*percentageOfDataset/batchSize)):\n",
        "\n",
        "    X = []\n",
        "    labels = []\n",
        "\n",
        "    # Make the batch\n",
        "    for i in range(batchSize):\n",
        "      offset = b * batchSize\n",
        "      X.append(encodeSelector(dataset[i + offset][0], dataset[i + offset][1], moveMap))\n",
        "      labels.append(dataset[i + offset][2])\n",
        "\n",
        "    optim.zero_grad()\n",
        "\n",
        "    X = torch.tensor(X).float()\n",
        "    output = moveSelector(X)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(batchSize):\n",
        "      #expectedOutput = moveLabel(labels[i], moveMap)\n",
        "      #loss += getMoveLoss(output[i], expectedOutput, 3)\n",
        "      loss += getMoveLossV1(output[i], labels[i], moveMap, weighting=1)\n",
        "\n",
        "    loss.backward()\n",
        "    runningLoss += loss.item()\n",
        "    optim.step()\n",
        "\n",
        "  else:\n",
        "    print(e, runningLoss/len(dataset)*percentageOfDataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF6ZMksqYQ05",
        "outputId": "9821c498-047a-494e-c1a3-fe308d403b56"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Positions Training On:  502652\n",
            "Estimated Training Time:  502  minutes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.009276234898100621\n",
            "1 0.009261030925939584\n",
            "2 0.009254120497614154\n",
            "3 0.009248720852047067\n",
            "4 0.009242029655203222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save Model\n",
        "\n",
        "newModelFile = 'MoveSelectorV1.4.pt'\n",
        "torch.save(moveSelector, os.path.join(chess_dir, newModelFile))"
      ],
      "metadata": {
        "id": "cdmFawZVsCh7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "labels = []\n",
        "for i in range(batchSize):\n",
        "  X.append(encodeSelector(dataset[i][0], dataset[i][1], moveMap))\n",
        "  labels.append(dataset[i][2])\n",
        "\n",
        "X = torch.tensor(X).float()\n",
        "testData = moveSelector(X)\n",
        "\n",
        "rankings = []\n",
        "for i in range(batchSize):\n",
        "  index = dict(decodeLegalMoves(X[i][-NUM_MOVE_NODES:], testData[i], moveMap))[labels[i]]\n",
        "  rankings.append(sorted(testData[i].tolist(), reverse=True).index(index))\n",
        "print(rankings)\n",
        "\n",
        "dataPoint = 20\n",
        "torch.set_printoptions(threshold=torch.inf)\n",
        "#print(testData[dataPoint])\n",
        "print(labels[dataPoint])\n",
        "print(decodeLegalMoves(X[dataPoint][-NUM_MOVE_NODES:], testData[dataPoint], moveMap))\n",
        "print(sorted(testData[dataPoint].tolist(), reverse=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYe7GYrCY1pG",
        "outputId": "fbaa4fe5-403a-4396-a9c7-28be9520d7a0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 33, 1, 0, 281, 1396, 287, 0, 1203, 1175, 347, 1750, 299, 69, 1461, 31, 615, 24, 208, 421, 607, 77, 82, 89, 931, 26, 808, 830, 1009, 1386, 109, 1034, 601, 193, 1589, 615, 471, 125, 541, 9, 28, 181, 855, 1306, 336, 1103, 1, 1235, 249, 124, 6, 1709, 1184, 16, 1655, 399, 598, 158, 1053, 76, 347, 1689, 139, 546, 1720, 375, 1240, 1396, 1164, 1419, 1154, 1183, 462, 1594, 1607, 1601, 830, 100, 6, 207, 58, 112, 1299, 436, 93, 92, 1548, 458, 527, 246, 0, 9, 0, 145, 55, 12, 0, 115, 195, 1452, 1193, 0, 13, 16, 0, 132, 953, 54, 1305, 254, 1435, 63, 758, 0, 6, 274, 96, 278, 13, 1614, 559, 1306, 655, 725, 204, 267, 330, 1684]\n",
            "d4h4\n",
            "[('a1a1', 1.2348982513649132e-12), ('a1b1', 1.324010068248782e-10), ('a3a4', 3.222514052478309e-12), ('b2b3', 4.157274351157536e-12), ('b2b4', 1.6805270282999052e-12), ('c1d2', 1.0106917473079458e-12), ('d4c3', 7.897517275562427e-13), ('d4c5', 3.4001799856589465e-13), ('d4d1', 1.331926539546724e-12), ('d4d2', 1.941360050147778e-12), ('d4d3', 1.7919338972730015e-12), ('d4d5', 9.521215413310635e-12), ('d4d6', 2.3975296574441085e-12), ('d4e4', 9.77920175393443e-12), ('d4e5', 6.208866428804305e-13), ('d4f4', 1.4566514227459804e-12), ('d4f6', 6.091377944585086e-13), ('d4g4', 1.0103217091064765e-12), ('d4h4', 1.576692769400534e-12), ('e1d1', 2.0224373391275474e-12), ('e1d2', 4.289281169828074e-12), ('e1f1', 1.613750582815654e-12), ('e1g1', 1.5798506166481152e-12), ('e2d1', 9.398446647670977e-13), ('e2d3', 8.573523835320174e-13), ('e2f1', 7.442245604505349e-13), ('e2f3', 6.715434415147103e-13), ('e2g4', 2.810870026320744e-13), ('e2h5', 3.7945642179619543e-13), ('e3e4', 1.0), ('f2f3', 1.7234634943144589e-12), ('f2f4', 2.7122525145945042e-12), ('g2g3', 3.956396099624726e-08), ('g2g4', 7.041568391742692e-13), ('h1f1', 9.095102058639948e-13), ('h1g1', 2.1378272416217037e-12), ('h2h3', 1.4314582505448037e-12), ('h2h4', 9.283566753878758e-13)]\n",
            "[1.0, 3.956396099624726e-08, 4.44690839707107e-10, 1.324010068248782e-10, 1.364241358770002e-11, 1.3013685615237414e-11, 1.2343195909814142e-11, 1.149834567837349e-11, 1.023489973328573e-11, 1.0043660347847094e-11, 9.77920175393443e-12, 9.521215413310635e-12, 9.410774243212572e-12, 8.42196971884146e-12, 8.32231072250833e-12, 8.205984503018016e-12, 7.710573499131179e-12, 7.602667627393256e-12, 7.231542187985385e-12, 7.145519852896909e-12, 6.620170123899927e-12, 6.454306707148749e-12, 6.428371290140289e-12, 6.387829501464104e-12, 6.253783949028424e-12, 6.19718035568817e-12, 6.157603073264628e-12, 6.05724932017937e-12, 5.9180056688479254e-12, 5.906131486654864e-12, 5.843316282228006e-12, 5.680803050189809e-12, 5.670605478236279e-12, 5.658418178455804e-12, 5.642596632993158e-12, 5.56472446247569e-12, 5.544795525502799e-12, 5.49091067753027e-12, 5.4029575952130315e-12, 5.354953459824063e-12, 5.345014361668454e-12, 5.332611522496089e-12, 5.188496333963233e-12, 5.183234050298857e-12, 5.1321290966965805e-12, 5.090781962646673e-12, 5.089694724708105e-12, 5.081139502205456e-12, 5.011608315841354e-12, 4.986883302138256e-12, 4.93365678172486e-12, 4.920884880132981e-12, 4.91721593998129e-12, 4.90658295243529e-12, 4.90625508969833e-12, 4.777405901434939e-12, 4.7610596021208096e-12, 4.66157754758223e-12, 4.636969627713761e-12, 4.602675011955437e-12, 4.5752789577802044e-12, 4.561789748031009e-12, 4.5364623516008784e-12, 4.504981457320589e-12, 4.493841930519604e-12, 4.437820770586409e-12, 4.428291500852e-12, 4.3936711907610615e-12, 4.3921628486987e-12, 4.301184842320227e-12, 4.292382855403121e-12, 4.289281169828074e-12, 4.255179108375584e-12, 4.253824289340846e-12, 4.2382503756543954e-12, 4.238088612690261e-12, 4.223249354395886e-12, 4.210846081542652e-12, 4.2015961022878745e-12, 4.185710805737486e-12, 4.157274351157536e-12, 4.154539559597659e-12, 4.137553147320894e-12, 4.132080094754187e-12, 4.127660886699136e-12, 4.127613615484416e-12, 4.125504191737628e-12, 4.122153573343779e-12, 4.110886544367309e-12, 4.108511274247828e-12, 4.072085984380136e-12, 4.0683827834397945e-12, 4.0362912664959616e-12, 4.031105744345398e-12, 3.994680454477706e-12, 3.992113497414129e-12, 3.991626473798249e-12, 3.989510544838426e-12, 3.9866274344213526e-12, 3.983815013985925e-12, 3.968518222374762e-12, 3.923368574465513e-12, 3.910697286835241e-12, 3.901168884462569e-12, 3.8562265360087e-12, 3.819530629278756e-12, 3.81316896461148e-12, 3.777192534443197e-12, 3.7513239042885616e-12, 3.721442425053123e-12, 3.71995186390639e-12, 3.715392576930654e-12, 3.710244351334824e-12, 3.701493538760259e-12, 3.6970274931713565e-12, 3.6894758081995604e-12, 3.612632762384216e-12, 3.610896737865632e-12, 3.606415947127184e-12, 3.6062164539274466e-12, 3.6020025937638644e-12, 3.572124583975378e-12, 3.5647873541932995e-12, 3.5592299506975733e-12, 3.5537827021425716e-12, 3.5529424454588954e-12, 3.5466523381350035e-12, 3.5390436241289347e-12, 3.532987053952996e-12, 3.528293325907872e-12, 3.5134720653695606e-12, 3.5025122992887736e-12, 3.5007892851962596e-12, 3.4965517894253173e-12, 3.4940516192155657e-12, 3.4934186619872687e-12, 3.490614481488352e-12, 3.4882984088074886e-12, 3.4849334789449626e-12, 3.4809939219310193e-12, 3.480522727666857e-12, 3.4723137993381004e-12, 3.4650823876880565e-12, 3.4645075436962047e-12, 3.4637212802807182e-12, 3.4606770574208134e-12, 3.4567385846090426e-12, 3.4532921227431457e-12, 3.415847465992883e-12, 3.4150655393860863e-12, 3.3996176099920783e-12, 3.399293433542505e-12, 3.387933596860071e-12, 3.3770690237300283e-12, 3.369033567748869e-12, 3.3572498080169932e-12, 3.3333860845197183e-12, 3.330767736273166e-12, 3.3293639113002316e-12, 3.3269136143904143e-12, 3.3231718158527324e-12, 3.3137789387516214e-12, 3.3045827359245994e-12, 3.2824704326167575e-12, 3.277171936599821e-12, 3.2759845183805147e-12, 3.2572304228817295e-12, 3.237737768863047e-12, 3.2225324839152414e-12, 3.222514052478309e-12, 3.219116813391043e-12, 3.219098381954111e-12, 3.217214038578331e-12, 3.1890007128054787e-12, 3.186598988152989e-12, 3.1855538172587128e-12, 3.179841372852321e-12, 3.1753445359217203e-12, 3.1710714783195204e-12, 3.1710471921908567e-12, 3.1614569902943535e-12, 3.157220795566018e-12, 3.156064819209714e-12, 3.1481887409479103e-12, 3.1394641660659195e-12, 3.133362276239171e-12, 3.130757588939992e-12, 3.118884924629972e-12, 3.1168928115582473e-12, 3.107146484548906e-12, 3.10327284702705e-12, 3.102657453873947e-12, 3.0979858435531415e-12, 3.088104208112674e-12, 3.082031591744583e-12, 3.07565995241732e-12, 3.06933666850695e-12, 3.0615837556119407e-12, 3.05322130425556e-12, 3.0518356938791236e-12, 3.0414050184585095e-12, 3.0407031059720424e-12, 3.020840522172108e-12, 3.0206332227167287e-12, 3.0182028751268852e-12, 3.0102344228399858e-12, 2.9995053749815037e-12, 2.9874238933330632e-12, 2.960892598810605e-12, 2.9572522815962676e-12, 2.956372559953513e-12, 2.9451499832661154e-12, 2.93842814663714e-12, 2.9329798138799656e-12, 2.931670965017341e-12, 2.9316319337391317e-12, 2.9212274960110918e-12, 2.9197180697465575e-12, 2.9158667667894544e-12, 2.907846923319579e-12, 2.8787809809582843e-12, 2.8720242330193546e-12, 2.8635678897548367e-12, 2.846403668321784e-12, 2.832717567458065e-12, 2.8310648096663282e-12, 2.8288569403622787e-12, 2.8221043123916045e-12, 2.8202639876240276e-12, 2.806473369670881e-12, 2.798855765206998e-12, 2.7964865666196825e-12, 2.785695719237369e-12, 2.7814482488064396e-12, 2.7733167325127983e-12, 2.77139726098663e-12, 2.7628945138691297e-12, 2.761361451997235e-12, 2.756204552784025e-12, 2.753661448168243e-12, 2.739339354310144e-12, 2.720609761780457e-12, 2.7199507837000203e-12, 2.7190584853120647e-12, 2.7122525145945042e-12, 2.7010550913975084e-12, 2.696304117477677e-12, 2.6678355705134216e-12, 2.6613507404793513e-12, 2.659579587810379e-12, 2.6524316597276165e-12, 2.6453331712639194e-12, 2.643310700531365e-12, 2.6360153209531445e-12, 2.6272161529616866e-12, 2.6240763034701686e-12, 2.617463103898876e-12, 2.6160206813286013e-12, 2.6108214982306643e-12, 2.6031342879873076e-12, 2.6011189729890916e-12, 2.598203553347278e-12, 2.5923031082841774e-12, 2.589426936761008e-12, 2.5778415860266968e-12, 2.5741761153219578e-12, 2.572507311338068e-12, 2.5660044835479345e-12, 2.5616082605789403e-12, 2.5510960531549554e-12, 2.5500112004611664e-12, 2.5462542230930696e-12, 2.545278224297398e-12, 2.5392799841983393e-12, 2.5362257866784477e-12, 2.5359644939548787e-12, 2.5345235892676454e-12, 2.531088619944777e-12, 2.529645763693633e-12, 2.5255286143638367e-12, 2.5133228831464294e-12, 2.5116120121182473e-12, 2.5063000719943718e-12, 2.5005798213323382e-12, 2.4877732252709395e-12, 2.474555499745734e-12, 2.4742677524891565e-12, 2.470556311612304e-12, 2.467824772658944e-12, 2.466083760810367e-12, 2.4636672910083313e-12, 2.4499746849315773e-12, 2.447742095817995e-12, 2.446197324562638e-12, 2.4429195645547797e-12, 2.4325463518493073e-12, 2.429305237874879e-12, 2.426036151484401e-12, 2.42489817288416e-12, 2.4212376895094145e-12, 2.4098119333348933e-12, 2.4043850677807344e-12, 2.4018228812067166e-12, 2.3975296574441085e-12, 2.3945589434914982e-12, 2.3900417235600546e-12, 2.378858394991301e-12, 2.3787402169545002e-12, 2.376468379722274e-12, 2.3570615945156526e-12, 2.3540559692530882e-12, 2.3459385475876893e-12, 2.3443729596506202e-12, 2.344229844963852e-12, 2.340396756603247e-12, 2.3394103494667196e-12, 2.3376040686473587e-12, 2.3318059722693407e-12, 2.326373035183016e-12, 2.3221791243394074e-12, 2.321492824364224e-12, 2.320669264394004e-12, 2.3080092524663254e-12, 2.3062094768599994e-12, 2.30160855652084e-12, 2.2941488118932707e-12, 2.289502355062867e-12, 2.2878083975885755e-12, 2.284398798596543e-12, 2.282465015601698e-12, 2.2816596702279757e-12, 2.281037338180969e-12, 2.276278341165061e-12, 2.2661070069041056e-12, 2.262077894790715e-12, 2.255817494606349e-12, 2.251403057040857e-12, 2.247905854513288e-12, 2.246135786046488e-12, 2.2435968013989616e-12, 2.2374727938478944e-12, 2.2363508614398064e-12, 2.230484894005791e-12, 2.221242504166221e-12, 2.220814677988958e-12, 2.2207340133473252e-12, 2.220158085153301e-12, 2.2184903653715837e-12, 2.2182321084140977e-12, 2.215813470207717e-12, 2.204250887719028e-12, 2.2027841790200897e-12, 2.1946272923956123e-12, 2.193334272884706e-12, 2.193162752101019e-12, 2.1897687656202702e-12, 2.187585399285319e-12, 2.1796470878188146e-12, 2.177116776788668e-12, 2.1760540418191976e-12, 2.1664378190705547e-12, 2.1638938470930347e-12, 2.163332664048556e-12, 2.162321970783365e-12, 2.162264291227789e-12, 2.1585968689591395e-12, 2.1562801457569725e-12, 2.156267785852206e-12, 2.1549519980956777e-12, 2.1396140068019598e-12, 2.1378272416217037e-12, 2.1346817542788887e-12, 2.1286967414463343e-12, 2.1275440176965477e-12, 2.1239557421864896e-12, 2.1201226538258844e-12, 2.11964170174217e-12, 2.109192378044189e-12, 2.101101627752233e-12, 2.1005246153560364e-12, 2.098510384559993e-12, 2.0907915156131995e-12, 2.083506544375835e-12, 2.079452929293346e-12, 2.075411457275189e-12, 2.073559639964584e-12, 2.072579087519788e-12, 2.071342012840982e-12, 2.0643649550206034e-12, 2.0627707441461807e-12, 2.0611897605382623e-12, 2.0601324465796544e-12, 2.058902961316056e-12, 2.0582903870886016e-12, 2.057748719683228e-12, 2.0548306979562003e-12, 2.0515451316927003e-12, 2.050539642597937e-12, 2.045172841844134e-12, 2.0444787356133087e-12, 2.0424480249442434e-12, 2.0395167759507116e-12, 2.031507340821692e-12, 2.029493326866083e-12, 2.0241237071866314e-12, 2.0224373391275474e-12, 2.021210889630032e-12, 2.018571941542202e-12, 2.0117802822933184e-12, 2.0114771393658915e-12, 2.010832689594566e-12, 2.0087972084359418e-12, 2.0066448502831236e-12, 2.0040134916105012e-12, 2.0012823863380103e-12, 1.9973927026240013e-12, 1.997122085761749e-12, 1.997110810059155e-12, 1.9970574673122687e-12, 1.9957132734588212e-12, 1.9938831401916657e-12, 1.9912418068590565e-12, 1.988050349344128e-12, 1.980730249956375e-12, 1.9768162801137024e-12, 1.976706992534716e-12, 1.97272970528517e-12, 1.9699246574245155e-12, 1.9654171953126243e-12, 1.964952506261497e-12, 1.9615674102385627e-12, 1.959122100658739e-12, 1.9575643189773118e-12, 1.9561125722683537e-12, 1.9514951720561724e-12, 1.9495754836895696e-12, 1.9495644248274102e-12, 1.9435312734183974e-12, 1.941360050147778e-12, 1.939957309377016e-12, 1.9335592155167447e-12, 1.933197742512438e-12, 1.932748015451291e-12, 1.930868876245939e-12, 1.919097693259264e-12, 1.9173963632101998e-12, 1.9119584387938815e-12, 1.9116121446199896e-12, 1.9113094353734317e-12, 1.906263558462684e-12, 1.906023516101696e-12, 1.9048350136802172e-12, 1.900023541279161e-12, 1.899907531646705e-12, 1.899882161315869e-12, 1.8982558580571407e-12, 1.898031428207436e-12, 1.8896149835828657e-12, 1.8893736401792705e-12, 1.8811462804135815e-12, 1.8782995991895035e-12, 1.8741197829741374e-12, 1.872354701837331e-12, 1.871794169314156e-12, 1.8713765346373146e-12, 1.871226697897077e-12, 1.8705057034523742e-12, 1.8644363396908004e-12, 1.863458606171653e-12, 1.8624743674394706e-12, 1.861018500762257e-12, 1.855630883326742e-12, 1.8542155658107795e-12, 1.8511201686083334e-12, 1.849468495018769e-12, 1.84798053595725e-12, 1.8462189242673954e-12, 1.845602880592989e-12, 1.8429047350665417e-12, 1.8413974772063524e-12, 1.8379692299369532e-12, 1.837597565432225e-12, 1.8301785868063414e-12, 1.8298784796449974e-12, 1.8274962706316122e-12, 1.826917740352374e-12, 1.8261546788633787e-12, 1.8249882941662188e-12, 1.823627837280184e-12, 1.820812597919108e-12, 1.819385787860117e-12, 1.8188479151623471e-12, 1.8186709733677975e-12, 1.8137137841947593e-12, 1.811943498887525e-12, 1.8086839534761645e-12, 1.8051995445342306e-12, 1.8051961835074959e-12, 1.7957488794573262e-12, 1.795587875434712e-12, 1.7949818064202927e-12, 1.7943896151936811e-12, 1.7931784529467976e-12, 1.7924397860066832e-12, 1.7919338972730015e-12, 1.791366642696357e-12, 1.7905570689341621e-12, 1.7899014518804601e-12, 1.7897034765637643e-12, 1.7882532477378477e-12, 1.780884033991681e-12, 1.7741846403476758e-12, 1.7674835119801946e-12, 1.7668026330158737e-12, 1.7654014101281534e-12, 1.7653844965742627e-12, 1.7621818717769577e-12, 1.7614996917700299e-12, 1.7613014996128995e-12, 1.7583409771607106e-12, 1.7570234546807062e-12, 1.7563164464440284e-12, 1.7556700451087925e-12, 1.755221402249818e-12, 1.7546021059688943e-12, 1.7528059082297376e-12, 1.752762431722621e-12, 1.74849848141867e-12, 1.7479982305362851e-12, 1.7477849679689572e-12, 1.7476848961084368e-12, 1.7466618429384795e-12, 1.7453597161293244e-12, 1.7447007380488877e-12, 1.7425921816638379e-12, 1.7424293344975306e-12, 1.7416285427729328e-12, 1.7382037649504856e-12, 1.7378158374131703e-12, 1.7358050760640786e-12, 1.7317211033207602e-12, 1.7276400579233075e-12, 1.7275610195849334e-12, 1.7254797850946302e-12, 1.7245749099614738e-12, 1.7234634943144589e-12, 1.7172617494676246e-12, 1.7157950407686862e-12, 1.709865539087363e-12, 1.7086494979307032e-12, 1.7086397401111508e-12, 1.7081053368603327e-12, 1.703858950631576e-12, 1.7038329297794363e-12, 1.7035567834861043e-12, 1.7028583404465891e-12, 1.7028323195944495e-12, 1.7020562476793843e-12, 1.7015206518061765e-12, 1.6999700258590877e-12, 1.6975691685683358e-12, 1.6931745719026003e-12, 1.6894809119413767e-12, 1.6886014071390565e-12, 1.6856826264705083e-12, 1.6814984734464522e-12, 1.6812643941974126e-12, 1.6805270282999052e-12, 1.6805045853149347e-12, 1.6784159782498587e-12, 1.6739464632140044e-12, 1.673732550125373e-12, 1.6677257448291516e-12, 1.6593902901068658e-12, 1.657685273770415e-12, 1.6563041086228858e-12, 1.655666055644378e-12, 1.6536809898867744e-12, 1.648736377458937e-12, 1.6451678344284182e-12, 1.6435181124027642e-12, 1.6426218024667705e-12, 1.6380664186188554e-12, 1.6352070522293594e-12, 1.6279778089836605e-12, 1.6270527676900959e-12, 1.626401162184432e-12, 1.6219248166748912e-12, 1.6217081930808286e-12, 1.619266461368174e-12, 1.61907195549843e-12, 1.6158049290920795e-12, 1.613750582815654e-12, 1.6132243110811295e-12, 1.6118402185877345e-12, 1.607115807621129e-12, 1.6067663692609369e-12, 1.6014916172715776e-12, 1.596550799551344e-12, 1.5947337851304755e-12, 1.593943184906299e-12, 1.5886679992360708e-12, 1.5856044775774958e-12, 1.5847095771043263e-12, 1.5798506166481152e-12, 1.5782062072131064e-12, 1.5781038585280238e-12, 1.576692769400534e-12, 1.5735863133359285e-12, 1.5731211906039322e-12, 1.5699379730255147e-12, 1.5693900172475406e-12, 1.5691057394379149e-12, 1.5680137310097875e-12, 1.5659693593933488e-12, 1.5644945191781168e-12, 1.5613673548520168e-12, 1.55976306089739e-12, 1.5574174979174349e-12, 1.5562743151467662e-12, 1.5558469226503724e-12, 1.5540585311668575e-12, 1.5535547024173035e-12, 1.5476750740359146e-12, 1.5459697324388122e-12, 1.5438776559267842e-12, 1.5436980036268033e-12, 1.542605995198676e-12, 1.5399925258618996e-12, 1.5363750853134017e-12, 1.5344539874839747e-12, 1.5341467245882923e-12, 1.5337516413166385e-12, 1.5328041570381035e-12, 1.5325907860505583e-12, 1.5306013834842647e-12, 1.5301401638800893e-12, 1.5257919710673362e-12, 1.525466059894287e-12, 1.5250645798298157e-12, 1.5218653160592455e-12, 1.5211020377298157e-12, 1.51870172254015e-12, 1.5177518530168355e-12, 1.5172338212188219e-12, 1.516516296221071e-12, 1.5156834121121676e-12, 1.5154956282958931e-12, 1.5128616675380568e-12, 1.5127578009699327e-12, 1.5122644889814518e-12, 1.5090862587330278e-12, 1.5086689493168381e-12, 1.5076449203649256e-12, 1.5072251172837392e-12, 1.506794038499959e-12, 1.5032000167183868e-12, 1.5026496756956331e-12, 1.5005932694350799e-12, 1.4971911514380376e-12, 1.4943980298012804e-12, 1.4931443668292355e-12, 1.4924582836944866e-12, 1.491940251896473e-12, 1.4898557647996524e-12, 1.485817545388013e-12, 1.4829524327270027e-12, 1.482375420330806e-12, 1.4791388600055022e-12, 1.478332213589173e-12, 1.4717796209193224e-12, 1.4674824940288933e-12, 1.4656139800048318e-12, 1.4649152117046649e-12, 1.4580690170865052e-12, 1.4577770414414548e-12, 1.4567958384753554e-12, 1.4566514227459804e-12, 1.4558652677507111e-12, 1.4546495518547031e-12, 1.4535429066972472e-12, 1.451323870110821e-12, 1.4512990418810712e-12, 1.4505849863302722e-12, 1.44959207398071e-12, 1.4458422523469516e-12, 1.445690572463021e-12, 1.4441279118718175e-12, 1.4434477918490174e-12, 1.441901285870184e-12, 1.4401257963925218e-12, 1.4388956606076198e-12, 1.438772278400391e-12, 1.4321546336001911e-12, 1.4314582505448037e-12, 1.4312316522907542e-12, 1.4294637522282994e-12, 1.4291040139474687e-12, 1.426612083674228e-12, 1.4251217393679294e-12, 1.4223735037011132e-12, 1.4211586551668431e-12, 1.4207060007598304e-12, 1.4200666467387157e-12, 1.418929535500213e-12, 1.4171930773007602e-12, 1.4169416508169608e-12, 1.416693151679027e-12, 1.413664541330406e-12, 1.4136187879987272e-12, 1.4120503811360097e-12, 1.4120126509004072e-12, 1.4114067987264223e-12, 1.4109331107972634e-12, 1.4057997387711962e-12, 1.4039561613971019e-12, 1.3999691163280037e-12, 1.3982719062471949e-12, 1.3975066763538546e-12, 1.396611342199816e-12, 1.3945324929542924e-12, 1.3940165211404065e-12, 1.393806511179596e-12, 1.391761055360985e-12, 1.391575223108621e-12, 1.391516784611524e-12, 1.3909515900190073e-12, 1.3897476919266794e-12, 1.3880177389402615e-12, 1.3879409774264495e-12, 1.384844496021831e-12, 1.3843401251711906e-12, 1.3810145518475259e-12, 1.3810013245810215e-12, 1.3787221147740225e-12, 1.37742107216704e-12, 1.3767802002628837e-12, 1.3744607665552855e-12, 1.3716428166887784e-12, 1.3653470715135896e-12, 1.3644307038374048e-12, 1.3638088054712671e-12, 1.3635903387335113e-12, 1.3618306786075673e-12, 1.3616722766701672e-12, 1.360153743107384e-12, 1.360005857931057e-12, 1.3588002251152531e-12, 1.3586783607910657e-12, 1.3564567221194257e-12, 1.356190333645646e-12, 1.3560634819914652e-12, 1.3557325834884226e-12, 1.3535698169947485e-12, 1.3526846743411314e-12, 1.352240910391933e-12, 1.351286920900363e-12, 1.3499705910427484e-12, 1.3487017492402886e-12, 1.3481694059735982e-12, 1.3480845129434926e-12, 1.3462036390146648e-12, 1.344181927223631e-12, 1.3434206004581117e-12, 1.3425625628588067e-12, 1.3425496608529541e-12, 1.3412724706937662e-12, 1.3385022257228485e-12, 1.3380810131788379e-12, 1.3339197368206213e-12, 1.3335102336600735e-12, 1.3329965386707499e-12, 1.3321018550380148e-12, 1.331926539546724e-12, 1.3315050017420615e-12, 1.3307432412956732e-12, 1.3271236323428304e-12, 1.3257701143506995e-12, 1.3255475276446882e-12, 1.3226155197096356e-12, 1.3219471090702983e-12, 1.3215337027819296e-12, 1.3210498233523493e-12, 1.3208004568526777e-12, 1.3156535322994545e-12, 1.315538173188302e-12, 1.314865967841361e-12, 1.3113345045251412e-12, 1.310646903507351e-12, 1.3103493984312209e-12, 1.3103469047662242e-12, 1.3100045137201533e-12, 1.3084014123879162e-12, 1.3067802048793986e-12, 1.3066631110447702e-12, 1.3055172177686702e-12, 1.3037032391138847e-12, 1.3025448775128012e-12, 1.3014498333185909e-12, 1.3011147064270756e-12, 1.30008764170908e-12, 1.2996637186596383e-12, 1.2992844647397028e-12, 1.299160648851605e-12, 1.2982787588045053e-12, 1.2971648494924937e-12, 1.2960841167669601e-12, 1.294367174206612e-12, 1.2943622952968359e-12, 1.2922408369059335e-12, 1.290336977891049e-12, 1.2899850458658602e-12, 1.2893357171847586e-12, 1.2844928029207003e-12, 1.2843555429256637e-12, 1.2765038592127409e-12, 1.2763893674633264e-12, 1.275778527959348e-12, 1.2736365781473857e-12, 1.2729783590084698e-12, 1.2726967917042753e-12, 1.2703733464486389e-12, 1.2671257272611758e-12, 1.2651648392120185e-12, 1.264658191536816e-12, 1.2617596854488933e-12, 1.2604079021802383e-12, 1.258282106980646e-12, 1.2566822582549264e-12, 1.2551085388015637e-12, 1.2526666986686918e-12, 1.2518522459967207e-12, 1.2514655110817952e-12, 1.2475950177462392e-12, 1.2454528510938423e-12, 1.2450846560360662e-12, 1.2446929337911472e-12, 1.2424324806817322e-12, 1.2422903417769193e-12, 1.2413050188425645e-12, 1.2410019843353548e-12, 1.2364561414665576e-12, 1.2356003806918148e-12, 1.2355414000936316e-12, 1.2348982513649132e-12, 1.2346744720365121e-12, 1.2323194764976564e-12, 1.232298334555293e-12, 1.2319833738241859e-12, 1.231849474855884e-12, 1.2299453990005649e-12, 1.2284496336834039e-12, 1.2281614527459572e-12, 1.2256972780483322e-12, 1.2253887141100428e-12, 1.225370065832676e-12, 1.2217620578430788e-12, 1.221414896307449e-12, 1.22048096455607e-12, 1.2165973523742268e-12, 1.2161194360565952e-12, 1.214702925918243e-12, 1.2142212148930076e-12, 1.2125756128356091e-12, 1.2072148836139718e-12, 1.2052638618045841e-12, 1.2045330011201116e-12, 1.2044871393682155e-12, 1.2020566833581547e-12, 1.2019282054007152e-12, 1.200894743889902e-12, 1.2006245607085186e-12, 1.2003634848253841e-12, 1.199397677530134e-12, 1.1993611399169213e-12, 1.1957978010568304e-12, 1.191647041459687e-12, 1.1913312133668419e-12, 1.1901501919403534e-12, 1.1895465081707135e-12, 1.1892719881806402e-12, 1.1878981956078838e-12, 1.1872933192158541e-12, 1.1826645348808618e-12, 1.1824592954096103e-12, 1.1820939192774826e-12, 1.1816904876491008e-12, 1.1806473767389525e-12, 1.1801722793469693e-12, 1.1796794010393574e-12, 1.17934199732328e-12, 1.1787460113890647e-12, 1.1784312674983921e-12, 1.1768140715379127e-12, 1.176255382158431e-12, 1.175160988485524e-12, 1.174833776269868e-12, 1.1745783382380304e-12, 1.172563782181335e-12, 1.171796925984736e-12, 1.171687421565315e-12, 1.169280818003049e-12, 1.1656244545965588e-12, 1.1623630660415052e-12, 1.1605266444017492e-12, 1.1593032306703166e-12, 1.1591396245624885e-12, 1.1586819828254824e-12, 1.1582312799823802e-12, 1.1576040690255973e-12, 1.1571404641766425e-12, 1.1544751699760214e-12, 1.1542836998723605e-12, 1.1539974704988243e-12, 1.1533043400499543e-12, 1.148551739826864e-12, 1.148551739826864e-12, 1.1481552470923861e-12, 1.1465314374986546e-12, 1.145672315697177e-12, 1.1444296031670742e-12, 1.1406269808875158e-12, 1.1392810523105923e-12, 1.1370451021702754e-12, 1.1354196662732852e-12, 1.1352161615255096e-12, 1.1348198856314662e-12, 1.1328671290986025e-12, 1.1321629397875732e-12, 1.1311505117989062e-12, 1.1298934878001266e-12, 1.1281620169306672e-12, 1.127632817850277e-12, 1.1263108501413654e-12, 1.1248831727206365e-12, 1.1213465052339888e-12, 1.1207905263599383e-12, 1.1185438426181138e-12, 1.1171345966343171e-12, 1.1142872648889357e-12, 1.113934465502009e-12, 1.1135372138260102e-12, 1.1129893664682533e-12, 1.1117461118370642e-12, 1.1110741233305577e-12, 1.106930302627318e-12, 1.104629300356652e-12, 1.1046124952229786e-12, 1.1034795039527312e-12, 1.0993304790790637e-12, 1.0990705958183189e-12, 1.0982909460360846e-12, 1.097939122431113e-12, 1.0959912448080256e-12, 1.0952765387359231e-12, 1.0948107654826233e-12, 1.09433686071303e-12, 1.0925787184701274e-12, 1.0924849349822074e-12, 1.0923202446722069e-12, 1.0878562590674323e-12, 1.0863281845255313e-12, 1.0849987358216295e-12, 1.0846739088507529e-12, 1.083865202450296e-12, 1.0825120097188168e-12, 1.0824727616001728e-12, 1.0772371493092403e-12, 1.0762164813840625e-12, 1.0741001187433707e-12, 1.072544288625854e-12, 1.0720943447242726e-12, 1.0718898641945418e-12, 1.0698309642689918e-12, 1.0690517481676265e-12, 1.0678534879265955e-12, 1.0640393731040088e-12, 1.0640352531357533e-12, 1.0639358317965364e-12, 1.0628121646649724e-12, 1.0622123840231534e-12, 1.0614913895784506e-12, 1.060400573772713e-12, 1.0603540614995133e-12, 1.059026130678653e-12, 1.0579762977150353e-12, 1.05703434286758e-12, 1.0570101651591335e-12, 1.0563893509951683e-12, 1.0561657885072018e-12, 1.0560469599490974e-12, 1.0543884558858463e-12, 1.0543824927738976e-12, 1.0531182046205623e-12, 1.052911338846052e-12, 1.0519137644271481e-12, 1.0512337528245652e-12, 1.0503879667098093e-12, 1.0503399365535682e-12, 1.0494448192399641e-12, 1.0489285221654265e-12, 1.0450503309944459e-12, 1.0445442254203297e-12, 1.043321679050635e-12, 1.0424881444204281e-12, 1.0415322033649477e-12, 1.03994016089487e-12, 1.039129286090068e-12, 1.0388815458936551e-12, 1.0387111093121404e-12, 1.0385209402510864e-12, 1.0382238688558254e-12, 1.0366270558961888e-12, 1.035947152713823e-12, 1.0359095308984378e-12, 1.0281912040527308e-12, 1.026772308669599e-12, 1.0246516092202174e-12, 1.0244405150572344e-12, 1.0237608287153033e-12, 1.0235616607762177e-12, 1.0195789525158094e-12, 1.0187974595898819e-12, 1.018494316662455e-12, 1.0169725304931543e-12, 1.0159256248754023e-12, 1.0146804186803027e-12, 1.01365324554209e-12, 1.0115325460927083e-12, 1.011220079026598e-12, 1.0106917473079458e-12, 1.0103217091064765e-12, 1.0093163284319306e-12, 1.008113839802427e-12, 1.0075294548314573e-12, 1.007029854470376e-12, 1.0063137389354493e-12, 1.0060201369871402e-12, 1.0058781065025446e-12, 1.004658595898933e-12, 1.0038522747432554e-12, 1.0036856328693444e-12, 1.0031095962551029e-12, 1.0030905142968671e-12, 1.0020253940826174e-12, 1.0009595149268469e-12, 1.00038683933934e-12, 9.994104068627996e-13, 9.98615795090585e-13, 9.967072740063587e-13, 9.966444987005718e-13, 9.955596460067828e-13, 9.945537232311508e-13, 9.943432795894713e-13, 9.938141889292984e-13, 9.937554251715497e-13, 9.91521318174926e-13, 9.912055985022983e-13, 9.878046731276457e-13, 9.866804638949955e-13, 9.844153487162388e-13, 9.817451756058415e-13, 9.799829133946836e-13, 9.79407310461311e-13, 9.787649206741134e-13, 9.787630775304201e-13, 9.78173271548588e-13, 9.775727319652483e-13, 9.751089909484922e-13, 9.73716983779238e-13, 9.731822552677682e-13, 9.725401907412223e-13, 9.720172800334326e-13, 9.719041977468423e-13, 9.711573992904343e-13, 9.711166332887489e-13, 9.710332581416847e-13, 9.666408298802942e-13, 9.654928766200666e-13, 9.635134487137598e-13, 9.620002277416217e-13, 9.614059765308824e-13, 9.60502402440333e-13, 9.590597630296238e-13, 9.584471888021695e-13, 9.56633643828253e-13, 9.561046615882973e-13, 9.558749191479476e-13, 9.552679827717903e-13, 9.541589523695548e-13, 9.531803514886694e-13, 9.510592183584188e-13, 9.505660147901551e-13, 9.498536939628321e-13, 9.49721421297789e-13, 9.48747374066028e-13, 9.480907812303707e-13, 9.468221562683454e-13, 9.45979189079238e-13, 9.446377057312216e-13, 9.443062651270928e-13, 9.427279920246057e-13, 9.413498626431593e-13, 9.406373249754019e-13, 9.398446647670977e-13, 9.391655205262528e-13, 9.38646079265415e-13, 9.370647703968449e-13, 9.366734818327949e-13, 9.34947431974198e-13, 9.329772197863573e-13, 9.328206609926504e-13, 9.327993022098524e-13, 9.326196499098716e-13, 9.32143034634847e-13, 9.318497579471896e-13, 9.299889417585527e-13, 9.283566753878758e-13, 9.2818667248723e-13, 9.272913383331916e-13, 9.264798130070862e-13, 9.261087990236616e-13, 9.252384015195902e-13, 9.2430175926278e-13, 9.241484530755906e-13, 9.232991975138827e-13, 9.232763208480432e-13, 9.22466638665631e-13, 9.212217577311832e-13, 9.18607421032669e-13, 9.18409445715973e-13, 9.181940147443002e-13, 9.179050748653328e-13, 9.167747941005167e-13, 9.151778727206628e-13, 9.133521846824144e-13, 9.133486068152452e-13, 9.12740911497567e-13, 9.12217025007822e-13, 9.095154100344227e-13, 9.095102058639948e-13, 9.094096461124968e-13, 9.083764014421181e-13, 9.083712514817988e-13, 9.070485248313664e-13, 9.063671037659593e-13, 9.054375088232702e-13, 9.053891534063774e-13, 9.051422263615938e-13, 9.03796623045322e-13, 9.014775688084842e-13, 9.013211184349945e-13, 8.991181822508298e-13, 8.97897966915806e-13, 8.974322478726149e-13, 8.97028382563364e-13, 8.96475927346374e-13, 8.932415354254153e-13, 8.932142677407773e-13, 8.929161663534524e-13, 8.924905085805346e-13, 8.888652075662862e-13, 8.873711227624925e-13, 8.867772510225136e-13, 8.855197391327563e-13, 8.852917856259912e-13, 8.852833288490458e-13, 8.849372515155884e-13, 8.845744232585662e-13, 8.839841293857564e-13, 8.836216805994945e-13, 8.833402759256259e-13, 8.812551925176104e-13, 8.80725885017003e-13, 8.781377318009542e-13, 8.779618742085771e-13, 8.770530417374911e-13, 8.769426157462235e-13, 8.768389118084252e-13, 8.762972444030515e-13, 8.753049825747927e-13, 8.747625562278982e-13, 8.737753901498502e-13, 8.71330568461004e-13, 8.688926314559531e-13, 8.683243468872448e-13, 8.678756498181617e-13, 8.666796664016929e-13, 8.643800193837425e-13, 8.638031696178716e-13, 8.632151525696241e-13, 8.603140443964874e-13, 8.602976729436829e-13, 8.577874738638358e-13, 8.573523835320174e-13, 8.569224431605182e-13, 8.556452530013303e-13, 8.554559513020144e-13, 8.536336785006093e-13, 8.524882189053784e-13, 8.496928746541677e-13, 8.489055812466173e-13, 8.487647433844114e-13, 8.483876036587124e-13, 8.476015570836604e-13, 8.472185084561212e-13, 8.468226662429468e-13, 8.454508794442095e-13, 8.416826805836275e-13, 8.41522164451991e-13, 8.410985124530923e-13, 8.375892752814085e-13, 8.373512929045479e-13, 8.372155507925527e-13, 8.359740850949482e-13, 8.356568475392789e-13, 8.348571400168536e-13, 8.340151486097014e-13, 8.334395456763288e-13, 8.322433454194256e-13, 8.301854754859395e-13, 8.284297184878164e-13, 8.261133747564098e-13, 8.244542743819638e-13, 8.221599941647673e-13, 8.186048952411873e-13, 8.183785138275723e-13, 8.177356903595057e-13, 8.137183960497951e-13, 8.135120181662625e-13, 8.134220293859462e-13, 8.129706760215405e-13, 8.125784658856439e-13, 8.125071795928029e-13, 8.123305088487964e-13, 8.114199958643431e-13, 8.113952218447018e-13, 8.099355604598846e-13, 8.078003869115002e-13, 8.07398310535834e-13, 8.071627134037529e-13, 8.061226924697962e-13, 8.040005835575903e-13, 8.027287601991562e-13, 8.007346955635208e-13, 7.988111582792057e-13, 7.986420227402979e-13, 7.976692223410353e-13, 7.971855597518895e-13, 7.968693521882841e-13, 7.96644434447602e-13, 7.964028742035723e-13, 7.935129333128121e-13, 7.932042067441969e-13, 7.920703481122116e-13, 7.917486111175265e-13, 7.912579554243682e-13, 7.905142469441517e-13, 7.904931592118969e-13, 7.903997009846286e-13, 7.903439187828543e-13, 7.897517275562427e-13, 7.887069903428356e-13, 7.887009730207784e-13, 7.886844389376479e-13, 7.884377829434075e-13, 7.873482681802768e-13, 7.872686877408164e-13, 7.867057699728619e-13, 7.850943744940053e-13, 7.847200536939547e-13, 7.831112603003121e-13, 7.830754274185114e-13, 7.82714062834422e-13, 7.825289353134701e-13, 7.824513064379202e-13, 7.819738780112662e-13, 7.817397987622265e-13, 7.814162728339569e-13, 7.812806391421789e-13, 7.805150839881869e-13, 7.792046088223037e-13, 7.78993623079538e-13, 7.783431017760467e-13, 7.783060220617477e-13, 7.779661246806735e-13, 7.77371331368848e-13, 7.773164707389202e-13, 7.770318676686427e-13, 7.751415611809143e-13, 7.749227691825067e-13, 7.733974593561455e-13, 7.733310519730807e-13, 7.723478432329622e-13, 7.709217379053834e-13, 7.695803629775844e-13, 7.684846682620705e-13, 7.680319054348406e-13, 7.680289780889749e-13, 7.660027668589253e-13, 7.644600013775871e-13, 7.64298129993235e-13, 7.635317616876136e-13, 7.634501754741341e-13, 7.612908784274119e-13, 7.606928325090689e-13, 7.590637645348008e-13, 7.580726953289318e-13, 7.578774847277758e-13, 7.576664989850102e-13, 7.56517027841741e-13, 7.547111807032492e-13, 7.538637682852345e-13, 7.530058391061467e-13, 7.522163230841428e-13, 7.522062942140473e-13, 7.519022297147737e-13, 7.485309572695387e-13, 7.478972953098295e-13, 7.478031865612578e-13, 7.475849908740451e-13, 7.475650415540713e-13, 7.469949138416698e-13, 7.449616552974991e-13, 7.446136264001313e-13, 7.445142050609144e-13, 7.442245604505349e-13, 7.440386197779536e-13, 7.425740794833602e-13, 7.399994245843589e-13, 7.398907333165672e-13, 7.396071602383536e-13, 7.384188746573095e-13, 7.377797374766293e-13, 7.373014416882373e-13, 7.367503959340715e-13, 7.36220817382921e-13, 7.353773623028359e-13, 7.346987601630772e-13, 7.344731919010916e-13, 7.302867078423647e-13, 7.291537165721174e-13, 7.289284735707835e-13, 7.282836443286977e-13, 7.28251714574718e-13, 7.276338819667272e-13, 7.275006335197287e-13, 7.273979595739943e-13, 7.270178925024295e-13, 7.238451916850852e-13, 7.219700098176629e-13, 7.215666323993897e-13, 7.215322089804133e-13, 7.206712440352425e-13, 7.200886479978574e-13, 7.181601233835488e-13, 7.178492826206972e-13, 7.144616929327663e-13, 7.133383510618541e-13, 7.128676988987781e-13, 7.127453466836131e-13, 7.117645231882741e-13, 7.113166392708203e-13, 7.105939101026415e-13, 7.103269253176669e-13, 7.091370134333641e-13, 7.084799869168379e-13, 7.071663675646545e-13, 7.061608242597828e-13, 7.061420133520901e-13, 7.05900940999038e-13, 7.053329816909815e-13, 7.045021033560972e-13, 7.041568391742692e-13, 7.02958470513021e-13, 7.02930335466645e-13, 7.021692255415601e-13, 7.021330131889991e-13, 7.01205586650655e-13, 7.005478554027167e-13, 7.001884965926464e-13, 6.991929821578702e-13, 6.979564495801505e-13, 6.978539924748506e-13, 6.973111324470871e-13, 6.971262759766783e-13, 6.96538801029517e-13, 6.963714002140853e-13, 6.958588978471514e-13, 6.956877023241159e-13, 6.955616638215645e-13, 6.930944533578565e-13, 6.922726823212211e-13, 6.868905943167858e-13, 6.868421304796757e-13, 6.866378125802708e-13, 6.862004996339988e-13, 6.84810606658981e-13, 6.847597033669828e-13, 6.846682509137336e-13, 6.842009597773924e-13, 6.839073578290833e-13, 6.836921436978449e-13, 6.83572230937568e-13, 6.827356605412782e-13, 6.817310930183618e-13, 6.804592696599276e-13, 6.803477052563789e-13, 6.775853749613203e-13, 6.774329361358689e-13, 6.768116882910347e-13, 6.767161700796387e-13, 6.76580644808078e-13, 6.756482851498491e-13, 6.752309215235508e-13, 6.751253202319507e-13, 6.748626180455575e-13, 6.743685471155558e-13, 6.732761050065594e-13, 6.715434415147103e-13, 6.70111644125726e-13, 6.698190179593722e-13, 6.690095526173945e-13, 6.674889590704836e-13, 6.656848466554677e-13, 6.644391525693905e-13, 6.64373287287412e-13, 6.640691685780298e-13, 6.631452114866376e-13, 6.617238224385091e-13, 6.615900318904244e-13, 6.601707028264236e-13, 6.588372967845924e-13, 6.581025871824076e-13, 6.577185627729132e-13, 6.576721589199308e-13, 6.545336104710198e-13, 6.541267636057946e-13, 6.523898175153642e-13, 6.522841078035468e-13, 6.519470293481211e-13, 6.518488006312939e-13, 6.490214182058862e-13, 6.489050833127785e-13, 6.478032628549901e-13, 6.464085451803048e-13, 6.437570745573828e-13, 6.429839299881834e-13, 6.428306780111026e-13, 6.411616571867784e-13, 6.403708943322761e-13, 6.401498797194149e-13, 6.401144805184833e-13, 6.398776365539038e-13, 6.383319437266999e-13, 6.360592391327358e-13, 6.344162933706599e-13, 6.339276434515206e-13, 6.322745061890234e-13, 6.317067637214013e-13, 6.312261911084471e-13, 6.307555931554798e-13, 6.304789589711701e-13, 6.291455529293388e-13, 6.282857263964492e-13, 6.271160348826632e-13, 6.257205040563485e-13, 6.247247727811378e-13, 6.239125969337289e-13, 6.232822417906458e-13, 6.220483112981401e-13, 6.216153893706666e-13, 6.208866428804305e-13, 6.189840849081529e-13, 6.164309514222754e-13, 6.162358492413367e-13, 6.148434083912135e-13, 6.139375574761019e-13, 6.137244575390999e-13, 6.099841768844594e-13, 6.098632341321186e-13, 6.092446967927156e-13, 6.091377944585086e-13, 6.071276294206118e-13, 6.068810818465886e-13, 6.066091097316206e-13, 6.036347637017325e-13, 6.025718661019364e-13, 6.016680209608438e-13, 6.012069097768857e-13, 6.011782326294235e-13, 6.009397623615853e-13, 5.984405137236803e-13, 5.977367038834114e-13, 5.970746358267831e-13, 5.946447761279172e-13, 5.92710722082529e-13, 5.92280185399835e-13, 5.905216094760635e-13, 5.893019362421259e-13, 5.888794226555083e-13, 5.877551050026408e-13, 5.874916980848355e-13, 5.872160938925897e-13, 5.869361528916539e-13, 5.855362310465406e-13, 5.852113498655553e-13, 5.836752522275779e-13, 5.819855231417592e-13, 5.818012629825453e-13, 5.791739158579612e-13, 5.766475079556355e-13, 5.764165728928961e-13, 5.753752509163323e-13, 5.75210669026549e-13, 5.739393877692012e-13, 5.726316231087492e-13, 5.718894325115742e-13, 5.709401050893459e-13, 5.697173960893254e-13, 5.685537218975967e-13, 5.68344470878307e-13, 5.654704135493738e-13, 5.651706316486815e-13, 5.639968743767487e-13, 5.632507806517528e-13, 5.629661775814754e-13, 5.6279655415159e-13, 5.627031501344304e-13, 5.616855179753355e-13, 5.616265915872609e-13, 5.612207747140996e-13, 5.590977984401557e-13, 5.531451490424499e-13, 5.48350807035719e-13, 5.47127447514395e-13, 5.466737089052098e-13, 5.440170883219686e-13, 5.424256421630858e-13, 5.405005869957291e-13, 5.404995570036653e-13, 5.395087046382308e-13, 5.392289262676209e-13, 5.371860725342237e-13, 5.368142453991698e-13, 5.347387571803808e-13, 5.33587497103527e-13, 5.318530446780934e-13, 5.315406860322003e-13, 5.313379402259455e-13, 5.307757813995118e-13, 5.304043879453268e-13, 5.303365710994379e-13, 5.301242301039566e-13, 5.288617850943145e-13, 5.287407881318651e-13, 5.286731881264106e-13, 5.278399245467469e-13, 5.252698775069786e-13, 5.240960118148286e-13, 5.235275104056858e-13, 5.22277858981679e-13, 5.221931827920079e-13, 5.217849806740671e-13, 5.209377308863783e-13, 5.195168297292274e-13, 5.190611937662404e-13, 5.190394013025734e-13, 5.182727619464089e-13, 5.171539737246211e-13, 5.170099374660064e-13, 5.14987466733452e-13, 5.123978498444703e-13, 5.118323299913019e-13, 5.100206823711873e-13, 5.088818364092085e-13, 5.063674089408887e-13, 5.062524835106053e-13, 5.06204182303821e-13, 5.042788018758126e-13, 5.009398386553177e-13, 5.002666575264214e-13, 4.998183941382073e-13, 4.98364804285556e-13, 4.970689658490013e-13, 4.94686485785073e-13, 4.936035304450859e-13, 4.93380455848097e-13, 4.93321149989262e-13, 4.929646643149488e-13, 4.918386119386053e-13, 4.906018625204511e-13, 4.894961389348418e-13, 4.871099725835271e-13, 4.844701571339594e-13, 4.838966683948231e-13, 4.836595533797006e-13, 4.828272113718834e-13, 4.820312985570618e-13, 4.817289145711556e-13, 4.811366149243268e-13, 4.79942366231334e-13, 4.798059735980353e-13, 4.790789618312752e-13, 4.790122833976673e-13, 4.7851094831311e-13, 4.784835722082548e-13, 4.767745443237659e-13, 4.758460335832493e-13, 4.758415341442335e-13, 4.757671036650923e-13, 4.753498484590113e-13, 4.73966514907137e-13, 4.737739606013036e-13, 4.724474392432676e-13, 4.712801329742611e-13, 4.70209862799692e-13, 4.692073552609033e-13, 4.687297099938148e-13, 4.612400955963936e-13, 4.601513939848922e-13, 4.60134697271436e-13, 4.590197037572519e-13, 4.582901441153864e-13, 4.568919027836404e-13, 4.564537766857391e-13, 4.56124829746607e-13, 4.559378048718532e-13, 4.550915850762283e-13, 4.5412995195934225e-13, 4.506861463887679e-13, 4.5048074428719054e-13, 4.498204922692012e-13, 4.480411538738266e-13, 4.4791470879546047e-13, 4.417836539302722e-13, 4.4102677239366006e-13, 4.3823950544863433e-13, 4.3786770541863473e-13, 4.354773106788473e-13, 4.273502125090589e-13, 4.270650131275866e-13, 4.260139062264162e-13, 4.252369940546674e-13, 4.2311889669049974e-13, 4.228590947449179e-13, 4.198021325094864e-13, 4.1712274368062296e-13, 4.163406002333919e-13, 4.15677258239211e-13, 4.1559323257084335e-13, 4.1152931756771594e-13, 4.0982094020453053e-13, 4.097295148563357e-13, 4.094178067317461e-13, 4.07951558818731e-13, 4.0735831049500126e-13, 4.070553844080088e-13, 4.0663479528024737e-13, 4.0596988119291633e-13, 4.045368098663793e-13, 3.997186154118537e-13, 3.976638896646678e-13, 3.9722042387106693e-13, 3.9712799563586254e-13, 3.951371022915817e-13, 3.942014087116724e-13, 3.9395786979867786e-13, 3.9163087378092654e-13, 3.8976713024642395e-13, 3.889717324276343e-13, 3.888500849438814e-13, 3.8520930694362077e-13, 3.81229417608861e-13, 3.804768457758845e-13, 3.803266566699409e-13, 3.801148848806002e-13, 3.7945642179619543e-13, 3.792198217771048e-13, 3.790983369236778e-13, 3.7904916835515556e-13, 3.774525993410077e-13, 3.766693987966585e-13, 3.7315902321269356e-13, 3.7284457747761846e-13, 3.705193161833431e-13, 3.6994590875936983e-13, 3.6925996114989257e-13, 3.688404291192493e-13, 3.6870116335019354e-13, 3.679382373864698e-13, 3.6732959339189075e-13, 3.670347446110833e-13, 3.658088914247626e-13, 3.6506447821313404e-13, 3.6404443370420536e-13, 3.62862463600816e-13, 3.6138025081081104e-13, 3.6013547829658044e-13, 3.5889366023326985e-13, 3.584783836961536e-13, 3.5328909394304053e-13, 3.5277396238583836e-13, 3.524995508159823e-13, 3.5247737888155495e-13, 3.509773038607583e-13, 3.489607691350982e-13, 3.447235986248076e-13, 3.4441731151108046e-13, 3.437590652671102e-13, 3.409791980019117e-13, 3.4001799856589465e-13, 3.3778145211438293e-13, 3.3713458999322377e-13, 3.3664881320984164e-13, 3.3416089448463915e-13, 3.321275546253055e-13, 3.3072860856214747e-13, 3.287029936432928e-13, 3.26676673993026e-13, 3.257315749592704e-13, 3.2376309749490573e-13, 3.1784755491655325e-13, 3.1592252685425093e-13, 3.1438306818953876e-13, 3.134956758164137e-13, 3.13452632990166e-13, 3.082065310432147e-13, 3.0646494998849694e-13, 3.0398375331676386e-13, 3.0298235708520194e-13, 2.9862261751931185e-13, 2.9577132843600085e-13, 2.9007438812067576e-13, 2.8820923512334895e-13, 2.852375182837291e-13, 2.8523152806672614e-13, 2.814426751547583e-13, 2.810870026320744e-13, 2.8030748837511166e-13, 2.797082498343789e-13, 2.796986546451524e-13, 2.7862841157563767e-13, 2.702532479487846e-13, 2.685867478945114e-13, 2.668160018013538e-13, 2.6535232886849835e-13, 2.648285236939163e-13, 2.640054516146739e-13, 2.6236196375151177e-13, 2.575147126787636e-13, 2.57215771034755e-13, 2.520152326841024e-13, 2.5159163489531233e-13, 2.467324575986668e-13, 2.412592966117427e-13, 2.4063658509397567e-13, 2.392407561120635e-13, 2.388427183894898e-13, 2.2831430214302617e-13, 2.2610328865267648e-13, 2.2252994802754444e-13, 2.1565874899678178e-13, 2.1379363665703643e-13, 2.1338176180423635e-13, 2.1216305079972686e-13, 2.08031278293129e-13, 2.0620892417656106e-13, 2.056939416971576e-13, 2.012554483959636e-13, 2.002010482306943e-13, 1.9478350681521872e-13, 1.9405890739829235e-13, 1.8909662247504344e-13, 1.8627788656196131e-13, 1.8512463426361564e-13, 1.827195621369182e-13, 1.8229730604831657e-13, 1.7907746954152343e-13, 1.7598096103185051e-13, 1.7280412669372358e-13, 1.6797281339291092e-13, 1.6505919623720916e-13, 1.6195158820779543e-13, 1.6136544140829545e-13, 1.3138374123453783e-13, 1.2037814050690904e-13, 1.199442834550618e-13, 4.763661456941813e-14, 1.721437933605713e-14, 6.628688839282549e-15, 8.462090091897485e-17]\n"
          ]
        }
      ]
    }
  ]
}