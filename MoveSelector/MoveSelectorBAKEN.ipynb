{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/averyrair/ChessBAKEN/blob/kenny/MoveSelector/MoveSelectorBAKEN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "\n",
        "!pip install chess\n",
        "#!pip install stockfish\n",
        "#!apt install stockfish"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMHzza4EUkGk",
        "outputId": "06e557fa-8562-4d53-8e8f-76c41692a354",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chess\n",
            "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: chess\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=8d21c803f15c2f29a6ed600bf38cf3d8bbcb3711a6a63456dcb244a03f9ba3c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
            "Successfully built chess\n",
            "Installing collected packages: chess\n",
            "Successfully installed chess-1.11.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Directories\n",
        "\n",
        "from google.colab import drive\n",
        "# For this to work, you need to have the \"Chess Bot BAKEN\" project shared with\n",
        "# the SAME email you linked this Colab to, presumably your GitHub email address.\n",
        "drive.mount('/content/drive', force_remount=1)\n",
        "chess_dir = '/content/drive/Shareddrives/Chess Bot BAKEN'"
      ],
      "metadata": {
        "id": "dR6-7kOo5ybX",
        "outputId": "7c1b1466-fe9f-4b39-ad5a-eedf0f7a3e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U1gs1RsOT7Ha",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import Libraries\n",
        "\n",
        "import os\n",
        "import chess\n",
        "import chess.pgn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Custom Board Representation\n",
        "\n",
        "def customBoardRep(board):\n",
        "\n",
        "  return board.fen().split(\" \")[0]"
      ],
      "metadata": {
        "id": "VEEak8R7EdJ5",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import PGN and Export CSV\n",
        "\n",
        "import chess.pgn\n",
        "#if not os.path.exists(os.path.join(chess_dir, 'moveSelectorDataset.csv')):\n",
        "if 0:\n",
        "  pgn_dir = os.path.join(chess_dir, 'KingBase2019-pgn')\n",
        "  pgnFiles = [os.path.join(pgn_dir, f) for f in os.listdir(pgn_dir) if f.endswith('.pgn')]\n",
        "\n",
        "  # Read every PGN file in the directory.\n",
        "  iterator = 0\n",
        "  for pgnFile in pgnFiles:\n",
        "    print(pgnFile)\n",
        "    pgn = open(pgnFile)\n",
        "\n",
        "    # Prepare CSV to export dataset.\n",
        "    with open(os.path.join(chess_dir, 'moveSelectorDataset' + pgnFile[74:81] +'.csv'), 'w') as csvfile:\n",
        "      csvwriter = csv.writer(csvfile)\n",
        "      #csvwriter.writeheader(['Label', 'Input'])\n",
        "\n",
        "      # Read every game in the PGN file.\n",
        "      while True:\n",
        "        game = chess.pgn.read_game(pgn)\n",
        "        if game is None: break\n",
        "        iterator += 1\n",
        "        if iterator % 500 == 0:\n",
        "          print(iterator)\n",
        "          #break\n",
        "        board = game.board()\n",
        "\n",
        "        # New data point for every move in the game.\n",
        "        gameMoves = list(game.mainline_moves())\n",
        "        for i in range(len(gameMoves)-1):\n",
        "          board.push(gameMoves[i])\n",
        "          legalMoves = \"\"\n",
        "          for m in list(board.legal_moves):\n",
        "            legalMoves = legalMoves + str(m) + \" \"\n",
        "          legalMoves = legalMoves.removesuffix(\" \")\n",
        "          #print(gameMoves[i+1], legalMoves, customBoardRep(board))\n",
        "          csvwriter.writerow([gameMoves[i+1], customBoardRep(board), legalMoves])"
      ],
      "metadata": {
        "id": "h-0ocmM9PmZo",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Fully-Connected Neural Network\n",
        "\n",
        "class myFCN(nn.Module):\n",
        "  def __init__(self, inSize, hiddenSizes, outSize):\n",
        "    super().__init__()\n",
        "    self.inSize = inSize\n",
        "    self.hiddenSize = hiddenSizes\n",
        "    self.outSize = outSize\n",
        "\n",
        "    self.lin1 = nn.Linear(inSize, hiddenSizes[0])\n",
        "    self.lin2 = nn.Linear(hiddenSizes[0], hiddenSizes[1])\n",
        "    self.lin3 = nn.Linear(hiddenSizes[1], outSize)\n",
        "\n",
        "    self.bn1 = nn.BatchNorm1d(hiddenSizes[0])\n",
        "    self.bn2 = nn.BatchNorm1d(hiddenSizes[1])\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax(dim=0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.bn1(self.lin1(x)))\n",
        "    x = self.relu(self.bn2(self.lin2(x)))\n",
        "    x = self.softmax(self.lin3(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "_xIwaUL2Ef0n",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Fully-Connected Neural Network\n",
        "\n",
        "currentModelFile = 'MoveSelectorV1.4.pt'\n",
        "\n",
        "moveSelector = myFCN(inSize=2560, hiddenSizes=[2200, 2200], outSize=1792)\n",
        "if (os.path.exists(os.path.join(chess_dir, currentModelFile))):\n",
        "  moveSelector = torch.load(os.path.join(chess_dir, currentModelFile), weights_only=False)\n",
        "  moveSelector.eval()\n",
        "  print(\"Loaded Model: \" + currentModelFile)\n",
        "print(moveSelector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtwHkKzU-30B",
        "outputId": "df2f66c1-4612-472c-c282-587a306c0785",
        "cellView": "form"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Model: MoveSelectorV1.4.pt\n",
            "myFCN(\n",
            "  (lin1): Linear(in_features=2560, out_features=2200, bias=True)\n",
            "  (lin2): Linear(in_features=2200, out_features=2200, bias=True)\n",
            "  (lin3): Linear(in_features=2200, out_features=1792, bias=True)\n",
            "  (bn1): BatchNorm1d(2200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm1d(2200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Dataset\n",
        "\n",
        "class ChessDataset(Dataset):\n",
        "    def __init__(self, chessgame_file, chess_dir, transform=None, target_transform=None):\n",
        "        self.game_labels = pd.read_csv(chessgame_file)\n",
        "        self.chess_dir = chess_dir  # This is not used. Everything is in the chessgame file.\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.game_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.game_labels.iloc[idx, 0]\n",
        "        gameState = self.game_labels.iloc[idx, 1]\n",
        "        moves = self.game_labels.iloc[idx, 2]\n",
        "\n",
        "        return gameState, moves, label"
      ],
      "metadata": {
        "id": "gEJ_xS5Kc-PN",
        "cellView": "form"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Encode/Decode Functions\n",
        "\n",
        "# The number of possible pieces and square states (8*8*6*2)\n",
        "NUM_BOARD_NODES = 768\n",
        "# The number of possible moves from any square to any other\n",
        "NUM_MOVE_NODES = 1792\n",
        "\n",
        "\n",
        "# Determines whether any piece could ever move from one square to another\n",
        "# Note: pass in start and end coordinates as tuples containing two ints\n",
        "def canMove(start, end):\n",
        "    # check duplicate\n",
        "    if start[0] == end[0] and start[1] == end[1]:\n",
        "        return False\n",
        "\n",
        "    # check row or col\n",
        "    if start[0] == end[0] or start[1] == end[1]:\n",
        "        return True\n",
        "\n",
        "    # check diagonal\n",
        "    if abs(start[0]-end[0]) == abs(start[1]-end[1]):\n",
        "        return True\n",
        "\n",
        "    # check knight\n",
        "    knightCases = [(1, 2), (1, -2), (-1, 2), (-1, -2),\n",
        "                   (2, 1), (2, -1), (-2, 1), (-2, -1)]\n",
        "    for c in knightCases:\n",
        "        if start[0] + c[0] == end[0] and start[1] + c[1] == end[1]:\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "# Generate the mapping matrix (only needs to be done once)\n",
        "def getMappingMatrix():\n",
        "    moveMap = [[[[0 for l in range(8)] for k in range(\n",
        "        8)] for j in range(8)] for i in range(8)]\n",
        "    offset = 0\n",
        "    for i in range(8):\n",
        "        for j in range(8):\n",
        "            for k in range(8):\n",
        "                for l in range(8):\n",
        "                    if canMove((i, j), (k, l)):\n",
        "                        moveMap[i][j][k][l] = offset\n",
        "                        offset += 1\n",
        "    return moveMap\n",
        "\n",
        "# Encode a board position and legal moves into a binary array\n",
        "def encodeSelector(boardFEN, moves, moveMap):\n",
        "    # Encode board position\n",
        "    encodedBoard = [0 for _ in range(NUM_BOARD_NODES)]\n",
        "    rowsFEN = boardFEN.split('/')\n",
        "    for i in range(8):\n",
        "        col = 0\n",
        "        for j in range(len(rowsFEN[i])):\n",
        "            if rowsFEN[i][j].isdigit():\n",
        "                col += ord(rowsFEN[i][j])-48\n",
        "            else:\n",
        "                match rowsFEN[i][j]:\n",
        "                    case 'P':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (0*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'N':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (1*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'B':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (2*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'R':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (3*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'Q':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (4*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'K':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (5*2) + 0\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'p':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (0*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'n':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (1*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'b':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (2*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'r':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (3*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'q':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (4*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                    case 'k':\n",
        "                        idx = (8*6*2*col) + (6*2*i) + (5*2) + 1\n",
        "                        encodedBoard[idx] = 1\n",
        "                col += 1\n",
        "\n",
        "    # Encode possible moves\n",
        "    encodedMoves = [0 for _ in range(NUM_MOVE_NODES)]\n",
        "    for m in moves.split(' '):\n",
        "        startCol = ord(str(m)[0])-97  # e.g. c -> 2\n",
        "        startRow = ord(str(m)[1])-49  # e.g. 8 -> 7\n",
        "        endCol = ord(str(m)[2])-97\n",
        "        endRow = ord(str(m)[3])-49\n",
        "        encodedMoves[(moveMap[startCol][startRow][endCol][endRow])] = 1\n",
        "\n",
        "    # Combine into single list\n",
        "    return encodedBoard + encodedMoves\n",
        "\n",
        "\n",
        "# Decode board position from a binary array of length 768\n",
        "def decodePosition(input):\n",
        "    # Create matrix of board\n",
        "    boardMatrix = [['.' for _ in range(8)] for _ in range(8)]\n",
        "\n",
        "    # Populate board\n",
        "    for i in range(len(input)):\n",
        "        if input[i] == 1:\n",
        "            piece = i % 12\n",
        "            # Piece: P = 0, R = 1, N = 2, B = 3, Q = 4, K = 5\n",
        "            # Color: W = 0, B = 1\n",
        "            pieceLabel = '.'\n",
        "            match piece:\n",
        "                case 0:\n",
        "                    pieceLabel = 'P'\n",
        "                case 1:\n",
        "                    pieceLabel = 'p'\n",
        "                case 2:\n",
        "                    pieceLabel = 'N'\n",
        "                case 3:\n",
        "                    pieceLabel = 'n'\n",
        "                case 4:\n",
        "                    pieceLabel = 'B'\n",
        "                case 5:\n",
        "                    pieceLabel = 'b'\n",
        "                case 6:\n",
        "                    pieceLabel = 'R'\n",
        "                case 7:\n",
        "                    pieceLabel = 'r'\n",
        "                case 8:\n",
        "                    pieceLabel = 'Q'\n",
        "                case 9:\n",
        "                    pieceLabel = 'q'\n",
        "                case 10:\n",
        "                    pieceLabel = 'K'\n",
        "                case 11:\n",
        "                    pieceLabel = 'k'\n",
        "            boardMatrix[int(i / (6*2)) % 8][int(i / (8*6*2))] = pieceLabel\n",
        "\n",
        "    # Convert to FEN notation\n",
        "    boardFEN = ''\n",
        "    for i in range(len(boardMatrix)):\n",
        "        empty = 0\n",
        "        for j in range(len(boardMatrix[i])):\n",
        "            if boardMatrix[i][j] == '.':\n",
        "                empty += 1\n",
        "            else:\n",
        "                if empty > 0:\n",
        "                    boardFEN += str(empty)\n",
        "                    empty = 0\n",
        "                boardFEN += boardMatrix[i][j]\n",
        "        if empty > 0:\n",
        "            boardFEN += str(empty)\n",
        "        if i < len(boardMatrix) - 1:\n",
        "            boardFEN += '/'\n",
        "\n",
        "    return chess.Board(boardFEN)\n",
        "\n",
        "\n",
        "# Decode moves from a binary array of length 1792\n",
        "# Returns a list of moves with start and end squares\n",
        "def decodeMoves(input, moveMap):\n",
        "    moves = []\n",
        "    for h in range(len(input)):\n",
        "        if input[h] > 0: # NOTE: may need to change this condition based on selector NN output\n",
        "            # Search moveMap to find the actual move squares\n",
        "            found = False\n",
        "            for i in range(8):\n",
        "                for j in range(8):\n",
        "                    for k in range(8):\n",
        "                        for l in range(8):\n",
        "                            if moveMap[i][j][k][l] == h:\n",
        "                                moves.append(chr(i+97) + chr(j+49) + chr(k+97) + chr(l+49))\n",
        "                                found = True\n",
        "                                break\n",
        "                        if found:\n",
        "                            break\n",
        "                    if found:\n",
        "                        break\n",
        "                if found:\n",
        "                    break\n",
        "    return moves\n",
        "\n",
        "def decodeLegalMoves(original, input, moveMap, threshold = 0):\n",
        "    indices = [i for i, x in enumerate(original) if x == 1]\n",
        "    moves = []\n",
        "    for h in indices:#range(len(input)):\n",
        "        if input[h] > threshold: # NOTE: may need to change this condition based on selector NN output\n",
        "            # Search moveMap to find the actual move squares\n",
        "            found = False\n",
        "            for i in range(8):\n",
        "                for j in range(8):\n",
        "                    for k in range(8):\n",
        "                        for l in range(8):\n",
        "                            if moveMap[i][j][k][l] == h:\n",
        "                                moves.append((chr(i+97) + chr(j+49) + chr(k+97) + chr(l+49), input[h].item()))\n",
        "                                found = True\n",
        "                                break\n",
        "                        if found:\n",
        "                            break\n",
        "                    if found:\n",
        "                        break\n",
        "                if found:\n",
        "                    break\n",
        "    return moves\n",
        "\n",
        "def moveLabel(moveMade, moveMap):\n",
        "    encodedMoves = [0 for _ in range(NUM_MOVE_NODES)]\n",
        "    startCol = ord(str(moveMade)[0])-97  # e.g. c -> 2\n",
        "    startRow = ord(str(moveMade)[1])-49  # e.g. 8 -> 7\n",
        "    endCol = ord(str(moveMade)[2])-97\n",
        "    endRow = ord(str(moveMade)[3])-49\n",
        "    encodedMoves[(moveMap[startCol][startRow][endCol][endRow])] = 1\n",
        "    return encodedMoves\n",
        "\n",
        "def getMoveLoss(modelOutput, expectedOutput, weighting = NUM_MOVE_NODES):\n",
        "    totalLoss = 0\n",
        "    for i in range(NUM_MOVE_NODES):\n",
        "        if expectedOutput[i] == 1:\n",
        "            # model should output value close to 1\n",
        "            totalLoss += abs(1 - modelOutput[i]) * weighting\n",
        "            pass\n",
        "        else:\n",
        "            # model should output value close to 0\n",
        "            totalLoss += abs(modelOutput[i])\n",
        "            pass\n",
        "    return totalLoss\n",
        "\n",
        "def getNewMoveLoss(modelOutput, moveMade, moveMap, weighting = NUM_MOVE_NODES):\n",
        "    startCol = ord(str(moveMade)[0])-97  # e.g. c -> 2\n",
        "    startRow = ord(str(moveMade)[1])-49  # e.g. 8 -> 7\n",
        "    endCol = ord(str(moveMade)[2])-97\n",
        "    endRow = ord(str(moveMade)[3])-49\n",
        "    totalLoss = torch.sum(modelOutput)\n",
        "    totalLoss += abs(1 - modelOutput[(moveMap[startCol][startRow][endCol][endRow])]) * weighting\n",
        "\n",
        "    return totalLoss\n",
        "\n",
        "### TESTING ###\n",
        "\n",
        "# Test the encoder and decoder\n",
        "def testEncodeDecode():\n",
        "    # Encode board\n",
        "    moveMap = getMappingMatrix()\n",
        "    with open(os.path.join(chess_dir, 'Move Selector Dataset', 'moveSelectorDatasetD70-D99.csv'), 'r') as file:\n",
        "        data = list(csv.reader(file))\n",
        "    curr = data[0]\n",
        "    encoded = encodeSelector(curr[1], curr[2], moveMap)\n",
        "\n",
        "    # Decode board\n",
        "    decodedBoard = decodePosition(encoded[0:NUM_BOARD_NODES])\n",
        "    decodedMoves = decodeMoves(encoded[-NUM_MOVE_NODES:], moveMap)\n",
        "\n",
        "    # Compare original and decoded position/moves\n",
        "    print('Original position and legal moves: ')\n",
        "    print(chess.Board(curr[1]))\n",
        "    print(sorted(curr[2].split(' ')))\n",
        "    print('---------------')\n",
        "    print('Decoded position and legal moves: ')\n",
        "    print(decodedBoard)\n",
        "    print(decodedMoves)\n",
        "\n",
        "#testEncodeDecode()"
      ],
      "metadata": {
        "id": "rBWRuqgqqlOj",
        "cellView": "form"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train Model\n",
        "\n",
        "dataset = ChessDataset(chessgame_file=os.path.join(chess_dir, 'Move Selector Dataset/moveSelectorDatasetA00-A39.csv'), chess_dir=chess_dir)\n",
        "moveMap = getMappingMatrix()\n",
        "\n",
        "optim = torch.optim.SGD(moveSelector.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "epochs = 4\n",
        "batchSize = 128\n",
        "percentageOfDataset = 0.1\n",
        "\n",
        "print(\"Number of Positions Training On: \", int(len(dataset)*percentageOfDataset))\n",
        "print(\"Estimated Training Time: \", int(len(dataset)*percentageOfDataset*epochs/100000), \" minutes\")\n",
        "\n",
        "for e in range(epochs):\n",
        "  runningLoss = 0\n",
        "\n",
        "  # Number of batches\n",
        "  for b in range(int(len(dataset)*percentageOfDataset/batchSize)):\n",
        "\n",
        "    X = []\n",
        "    labels = []\n",
        "\n",
        "    # Make the batch\n",
        "    for i in range(batchSize):\n",
        "      offset = b * batchSize\n",
        "      X.append(encodeSelector(dataset[i + offset][0], dataset[i + offset][1], moveMap))\n",
        "      labels.append(dataset[i + offset][2])\n",
        "\n",
        "    optim.zero_grad()\n",
        "\n",
        "    X = torch.tensor(X).float()\n",
        "    output = moveSelector(X)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(batchSize):\n",
        "      #expectedOutput = moveLabel(labels[i], moveMap)\n",
        "      #loss += getMoveLoss(output[i], expectedOutput, 3)\n",
        "      loss += getNewMoveLoss(output[i], labels[i], moveMap, 2)\n",
        "\n",
        "    loss.backward()\n",
        "    runningLoss += loss.item()\n",
        "    optim.step()\n",
        "\n",
        "  else:\n",
        "    print(e, runningLoss/len(dataset)*percentageOfDataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF6ZMksqYQ05",
        "outputId": "27c825a7-76fa-448e-fdf7-d373f8523d4a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Positions Training On:  502652\n",
            "Estimated Training Time:  1005  minutes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.028899882003761385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save Model\n",
        "\n",
        "newModelFile = 'MoveSelectorV1.4.pt'\n",
        "torch.save(moveSelector, os.path.join(chess_dir, newModelFile))"
      ],
      "metadata": {
        "id": "cdmFawZVsCh7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "labels = []\n",
        "for i in range(batchSize):\n",
        "  X.append(encodeSelector(dataset[i][0], dataset[i][1], moveMap))\n",
        "  labels.append(dataset[i][2])\n",
        "\n",
        "X = torch.tensor(X).float()\n",
        "testData = moveSelector(X)\n",
        "\n",
        "dataPoint = 0\n",
        "torch.set_printoptions(threshold=torch.inf)\n",
        "#print(testData[dataPoint])\n",
        "print(labels[dataPoint])\n",
        "print(decodeLegalMoves(X[dataPoint][-NUM_MOVE_NODES:], testData[dataPoint], moveMap))\n",
        "print(sorted(testData[dataPoint].tolist(), reverse=True))\n",
        "\n",
        "rankings = []\n",
        "for i in range(batchSize):\n",
        "  index = dict(decodeLegalMoves(X[i][-NUM_MOVE_NODES:], testData[i], moveMap))[labels[i]]\n",
        "  rankings.append(sorted(testData[i].tolist(), reverse=True).index(index))\n",
        "print(rankings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYe7GYrCY1pG",
        "outputId": "cacd62eb-3b7e-48fc-ca1a-e308f674ca0d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b1c3\n",
            "[('a2a3', 1.3448592066367393e-11), ('a2a4', 2.7644659131298432e-11), ('b1a3', 4.268721227190797e-12), ('b1c3', 0.9999997615814209), ('b2b3', 7.723303767359635e-12), ('b2b4', 4.842153154133166e-12), ('c4c5', 5.010297732255253e-12), ('d1a4', 9.255863436807843e-12), ('d1b3', 1.0603381887797081e-11), ('d1c2', 2.32592105298135e-11), ('d2d3', 2.2588503290066342e-10), ('d2d4', 1.414123332321715e-11), ('e2e3', 5.111480290138741e-14), ('e2e4', 3.515993746150414e-11), ('f2f3', 2.7686028816753527e-11), ('f2f4', 1.719812486866701e-11), ('g1f3', 3.773888146429982e-11), ('g1h3', 3.3236590563090473e-12), ('g2g3', 1.2513264380231703e-07), ('g2g4', 1.3282325543248485e-12), ('h2h3', 8.579170360234478e-12), ('h2h4', 4.96978109706947e-12)]\n",
            "[0.9999997615814209, 1.2513264380231703e-07, 1.0223601520920056e-07, 1.576616726062241e-09, 5.575874206797948e-10, 2.2588503290066342e-10, 2.1900126156992883e-10, 1.1098232055584134e-10, 1.0233086600308638e-10, 7.108249405751721e-11, 6.127985618942233e-11, 5.3241369646350734e-11, 4.9549427061368334e-11, 4.7002735037438015e-11, 4.6123958818977684e-11, 4.5653949370949576e-11, 4.507939507791825e-11, 4.469984452026843e-11, 4.03110669844331e-11, 4.023172073264192e-11, 3.868139142326754e-11, 3.7935033586622424e-11, 3.773888146429982e-11, 3.728669109581695e-11, 3.515993746150414e-11, 3.4303952040071195e-11, 3.4047192148944916e-11, 3.403933385159874e-11, 3.4020640471421615e-11, 3.22319115841907e-11, 3.130250919580746e-11, 3.113406060739621e-11, 3.099363821146284e-11, 3.014090366182387e-11, 3.0118376542764835e-11, 2.991256201068104e-11, 2.9357734993018525e-11, 2.9322926031749574e-11, 2.9082248761969076e-11, 2.8810778415766514e-11, 2.841755650240252e-11, 2.810925797680497e-11, 2.8099394339120565e-11, 2.779030824906492e-11, 2.7686028816753527e-11, 2.7655260026460127e-11, 2.7644659131298432e-11, 2.7544185682293332e-11, 2.744355263872844e-11, 2.7012978659479714e-11, 2.687899035291874e-11, 2.6423887383719702e-11, 2.6274874637133294e-11, 2.624252030958285e-11, 2.569996992995982e-11, 2.538791572803678e-11, 2.506903191978882e-11, 2.4960868441614714e-11, 2.4838055223685984e-11, 2.4623103903054222e-11, 2.4555893776700977e-11, 2.4020343006303513e-11, 2.3831096818138775e-11, 2.3707102253522905e-11, 2.3656196793120365e-11, 2.362959133916931e-11, 2.3444184094056908e-11, 2.3422952813434428e-11, 2.32592105298135e-11, 2.2980955680096393e-11, 2.2788897505177097e-11, 2.196286208455689e-11, 2.19289152808555e-11, 2.1784506490374334e-11, 2.1689025575533094e-11, 2.1637336020119413e-11, 2.1588361306945636e-11, 2.148394483147964e-11, 2.135692317439819e-11, 2.133204897447616e-11, 2.1300945382551895e-11, 2.1244223394334405e-11, 2.110887332984479e-11, 2.0909675033098374e-11, 2.059638050389001e-11, 2.0572783060446298e-11, 2.0509078810238002e-11, 2.0454620636156662e-11, 1.9987917571073766e-11, 1.998281054516049e-11, 1.9973245279913954e-11, 1.99219581803467e-11, 1.984932530840755e-11, 1.9833090031395884e-11, 1.9827983005482608e-11, 1.9768886180826506e-11, 1.9755955552036575e-11, 1.973396272780814e-11, 1.964735665827e-11, 1.9576545245980626e-11, 1.941445788855578e-11, 1.932029709827976e-11, 1.9305673379377275e-11, 1.9292126923753372e-11, 1.9087561392572283e-11, 1.9015468019634163e-11, 1.9014052485277766e-11, 1.8929054504401854e-11, 1.8823420253055723e-11, 1.8640953364235102e-11, 1.8322607320264694e-11, 1.830472405595085e-11, 1.8299452231307356e-11, 1.8182448602299672e-11, 1.814503235164633e-11, 1.809716265732675e-11, 1.8058613632243592e-11, 1.7906464505612618e-11, 1.7848734643055586e-11, 1.770912583243245e-11, 1.768630727982945e-11, 1.7590458603611303e-11, 1.7572316865499538e-11, 1.752024220147419e-11, 1.7513393513191033e-11, 1.739849410375971e-11, 1.7388011169794382e-11, 1.7363121357361067e-11, 1.7308366545565335e-11, 1.7258094259231527e-11, 1.7250229022991448e-11, 1.719812486866701e-11, 1.7189499823544452e-11, 1.709784397396774e-11, 1.7054689258055866e-11, 1.7023748730138344e-11, 1.686873210560158e-11, 1.6832542304445752e-11, 1.682865825858304e-11, 1.6822111412184704e-11, 1.6820570977738036e-11, 1.6816400702501788e-11, 1.675183082527898e-11, 1.6645769831957757e-11, 1.657619354278328e-11, 1.6502249219896292e-11, 1.643129902972884e-11, 1.6418016252073286e-11, 1.6378200878852667e-11, 1.637801352871726e-11, 1.6316619930178966e-11, 1.63163718647219e-11, 1.629251941692722e-11, 1.6269881275565723e-11, 1.6266498564787568e-11, 1.6265287727801336e-11, 1.6217954063035833e-11, 1.6162831489863194e-11, 1.6124619001134377e-11, 1.6096256272302156e-11, 1.6086926929448353e-11, 1.6062550595163927e-11, 1.603561380902896e-11, 1.5938736441789558e-11, 1.58874424033284e-11, 1.5873509104369354e-11, 1.5873358183426944e-11, 1.5755088206281798e-11, 1.574974005380536e-11, 1.5709928150031693e-11, 1.567257608414696e-11, 1.5662804386806783e-11, 1.5662774896507692e-11, 1.5617460449868226e-11, 1.5572635195248985e-11, 1.556132306346214e-11, 1.5560134777881096e-11, 1.55089951298093e-11, 1.5483782658809453e-11, 1.5393439994904057e-11, 1.5289124133399667e-11, 1.5278512829897117e-11, 1.5247188928091404e-11, 1.5236664360762653e-11, 1.5221938293175086e-11, 1.5202962153071375e-11, 1.516227421394234e-11, 1.5149208276721282e-11, 1.510307677532463e-11, 1.5064265806996602e-11, 1.50627999656594e-11, 1.506271496420908e-11, 1.5049704538139252e-11, 1.502598566405222e-11, 1.50167586698835e-11, 1.4909108669858284e-11, 1.489867604287376e-11, 1.489072060101293e-11, 1.4832555322863428e-11, 1.4830404265753216e-11, 1.4768106876283937e-11, 1.471084018489499e-11, 1.4658604191586377e-11, 1.4655389748985392e-11, 1.4644044657452504e-11, 1.4622553168308627e-11, 1.460095412630924e-11, 1.4589345356808003e-11, 1.4572242718058348e-11, 1.4518670120311494e-11, 1.4514046214886278e-11, 1.4511167441277895e-11, 1.4494901806605398e-11, 1.4462508447776745e-11, 1.445440035025003e-11, 1.4445222795700374e-11, 1.4289898257746625e-11, 1.4224579847343932e-11, 1.4187269414822623e-11, 1.4176746582217348e-11, 1.4144443429009446e-11, 1.4143203101724122e-11, 1.414123332321715e-11, 1.4082905848422644e-11, 1.4065939385465853e-11, 1.4055158079062657e-11, 1.4044466110918474e-11, 1.3950701704956714e-11, 1.393487929213233e-11, 1.3932008324779588e-11, 1.3920692723545791e-11, 1.3898460507477672e-11, 1.3887331389017543e-11, 1.3771087568892337e-11, 1.3765993553405131e-11, 1.3746760674226977e-11, 1.3743745724825729e-11, 1.3740652712868062e-11, 1.3696458030232339e-11, 1.3679566160385015e-11, 1.3665405612650616e-11, 1.3602837606319085e-11, 1.354709226741857e-11, 1.3493994116542396e-11, 1.3489876750372165e-11, 1.3475269511342702e-11, 1.3448592066367393e-11, 1.3441949810177878e-11, 1.342101950407848e-11, 1.3420968329735938e-11, 1.3399023210403094e-11, 1.339373403852484e-11, 1.3359672743074036e-11, 1.3347243449368662e-11, 1.3330374998288264e-11, 1.3208712769385844e-11, 1.319725405346528e-11, 1.317778611925613e-11, 1.3160830932001932e-11, 1.3150994182531406e-11, 1.313530187396772e-11, 1.311592414537932e-11, 1.3088659496507393e-11, 1.3085164896065038e-11, 1.3037855517428198e-11, 1.3031416223885373e-11, 1.3020137051844571e-11, 1.299440936797236e-11, 1.296081991730702e-11, 1.293942904212475e-11, 1.2930868181770805e-11, 1.2884878927699184e-11, 1.2847454870790198e-11, 1.284630301440215e-11, 1.2760075981943508e-11, 1.2738700719272522e-11, 1.2732385458458229e-11, 1.2671866160551826e-11, 1.2669931943876112e-11, 1.2618202489822483e-11, 1.2603601322325186e-11, 1.2569008334128995e-11, 1.2568840933313563e-11, 1.2541756695683137e-11, 1.2521630433914854e-11, 1.2515732374096533e-11, 1.2513154575011232e-11, 1.2495553203262233e-11, 1.2484071068574742e-11, 1.2474859686917306e-11, 1.2419992985457373e-11, 1.2413172052749832e-11, 1.241125431594714e-11, 1.2368669456697123e-11, 1.2327641511766796e-11, 1.2292281775794223e-11, 1.2270847532525053e-11, 1.2200159285602474e-11, 1.2198692576903536e-11, 1.2181022683577236e-11, 1.2084408126944446e-11, 1.208325540319466e-11, 1.208009907383012e-11, 1.207862455887554e-11, 1.203153462275841e-11, 1.2007439313677093e-11, 1.1969915510168239e-11, 1.1911906357131574e-11, 1.1879619683796694e-11, 1.1869269456177278e-11, 1.1845567061963269e-11, 1.1836668797893246e-11, 1.183231203988333e-11, 1.1826152904181875e-11, 1.1783395439945998e-11, 1.1715894747410527e-11, 1.1676943266480944e-11, 1.1662786188193497e-11, 1.1662119187016984e-11, 1.1626849656665161e-11, 1.1620752103647103e-11, 1.1611757562424163e-11, 1.1599361228464833e-11, 1.1579488236324043e-11, 1.1563178366202909e-11, 1.1554249744472056e-11, 1.1554205509023419e-11, 1.155255318491255e-11, 1.1541056305075514e-11, 1.147303953230594e-11, 1.1459218123011095e-11, 1.1430315895177845e-11, 1.1423123731646445e-11, 1.1411799456795269e-11, 1.1385037010369636e-11, 1.1371603311771672e-11, 1.1364599365737416e-11, 1.1354264750629284e-11, 1.1346535690182069e-11, 1.1271644208277198e-11, 1.1268677831133278e-11, 1.1247805638270325e-11, 1.1234233161794283e-11, 1.1216570207361887e-11, 1.1183735361408598e-11, 1.1136628945418448e-11, 1.1127604913896416e-11, 1.1097845732666034e-11, 1.108314395120713e-11, 1.1083102317843707e-11, 1.1050131296097554e-11, 1.1024889334798615e-11, 1.10150734020098e-11, 1.0996978501431887e-11, 1.0936297874242218e-11, 1.0888218278382045e-11, 1.0876968596640335e-11, 1.0844156302092234e-11, 1.0821613570521915e-11, 1.0814639982148488e-11, 1.0809669999389815e-11, 1.078909184215604e-11, 1.078074001598095e-11, 1.0746722088617044e-11, 1.0735311077592069e-11, 1.0731461726198877e-11, 1.0621072597805092e-11, 1.0617164265813717e-11, 1.0613134503179023e-11, 1.0603381887797081e-11, 1.0599338247374579e-11, 1.0580290983608354e-11, 1.0564118156641822e-11, 1.0551452073181977e-11, 1.0491948455870759e-11, 1.047836990786255e-11, 1.046716359420774e-11, 1.045383571374181e-11, 1.0409168318958884e-11, 1.0397064285905255e-11, 1.039190955509639e-11, 1.0382003416686825e-11, 1.03790734687359e-11, 1.0376816593493654e-11, 1.0357596724741569e-11, 1.0348908362212139e-11, 1.0348138144988805e-11, 1.0335237873859704e-11, 1.0327690959377467e-11, 1.0302232157644031e-11, 1.0279816060887459e-11, 1.0267001658570418e-11, 1.026265444153962e-11, 1.0258212682079382e-11, 1.0249177374854757e-11, 1.0245619457005528e-11, 1.0242845634167441e-11, 1.0185471389922984e-11, 1.0183936159646745e-11, 1.0171919730128653e-11, 1.0162766461707662e-11, 1.0152613992564508e-11, 1.0138913146551243e-11, 1.0131219647935286e-11, 1.0110140155616953e-11, 1.0106727087177969e-11, 1.0085775097035121e-11, 1.0084659669840068e-11, 1.0055158095045869e-11, 1.0048639871584886e-11, 1.004482608202295e-11, 1.0021154912831509e-11, 1.001045687315516e-11, 9.988218585554876e-12, 9.987208109130119e-12, 9.97900199972701e-12, 9.97896383581054e-12, 9.97319848233813e-12, 9.961430118277104e-12, 9.954839903791868e-12, 9.954137340784097e-12, 9.883570524504837e-12, 9.848287116365206e-12, 9.839538038514117e-12, 9.839162470881568e-12, 9.789388050185366e-12, 9.782482116027502e-12, 9.766225154972386e-12, 9.739048109635995e-12, 9.715911235275154e-12, 9.684292430478525e-12, 9.678032680815463e-12, 9.668512518379302e-12, 9.621160639017301e-12, 9.61140368682667e-12, 9.599000413973435e-12, 9.58739945072784e-12, 9.55452210404939e-12, 9.550787244405612e-12, 9.545250874432032e-12, 9.536879966298706e-12, 9.518071227010427e-12, 9.508074015618373e-12, 9.50020617729308e-12, 9.485684807075678e-12, 9.454148401644158e-12, 9.429602064459086e-12, 9.422104589595914e-12, 9.413751896059086e-12, 9.404132854384795e-12, 9.394397586237613e-12, 9.392892713622203e-12, 9.386159384450199e-12, 9.380360203870008e-12, 9.3187653774085e-12, 9.304380182983962e-12, 9.290406118023231e-12, 9.275249839013622e-12, 9.255969254939878e-12, 9.255863436807843e-12, 9.251256878617387e-12, 9.246528889783612e-12, 9.214187572659238e-12, 9.212658413915165e-12, 9.191473970826536e-12, 9.189072246174046e-12, 9.17593692001395e-12, 9.168099439349486e-12, 9.162609906909758e-12, 9.14998372208986e-12, 9.148814518467052e-12, 9.14628442427734e-12, 9.144714499531581e-12, 9.117318879037217e-12, 9.103677880983874e-12, 9.101126102750712e-12, 9.095260135316696e-12, 9.055224452214627e-12, 9.046092000475348e-12, 9.039520867948347e-12, 9.038176457254465e-12, 9.016962523866745e-12, 9.009329740572447e-12, 8.990738709080404e-12, 8.985852860410315e-12, 8.979358923077996e-12, 8.967532445780524e-12, 8.957617633753578e-12, 8.94150378738523e-12, 8.915924422370214e-12, 8.905471846065716e-12, 8.893488376293668e-12, 8.87855587661246e-12, 8.875068215064008e-12, 8.8708372245061e-12, 8.85756572255314e-12, 8.852261805525341e-12, 8.842693938193591e-12, 8.816589819327092e-12, 8.799101204604032e-12, 8.797624954925976e-12, 8.796785348763603e-12, 8.78514882368675e-12, 8.771252821282438e-12, 8.748445544382033e-12, 8.729493690406986e-12, 8.721555595780917e-12, 8.705301236811014e-12, 8.698446476995692e-12, 8.670783709086027e-12, 8.670651870101853e-12, 8.657662260713739e-12, 8.65048224024667e-12, 8.642813895121115e-12, 8.629257031156357e-12, 8.608905255336197e-12, 8.604538088985425e-12, 8.58021726585223e-12, 8.579170360234478e-12, 8.572774434778552e-12, 8.562576862825022e-12, 8.55464397236938e-12, 8.552212757417799e-12, 8.542447131609787e-12, 8.53046366183774e-12, 8.514777424806219e-12, 8.502102667728995e-12, 8.501340256761303e-12, 8.485804940672192e-12, 8.450803425097408e-12, 8.42558314784192e-12, 8.421389453838746e-12, 8.404749118895438e-12, 8.396017388279109e-12, 8.394960074320501e-12, 8.393118665350752e-12, 8.38113693030218e-12, 8.38005012604448e-12, 8.36315652147368e-12, 8.359887435083202e-12, 8.359201351948453e-12, 8.352030005098765e-12, 8.342015446471951e-12, 8.306324378315466e-12, 8.300701272168087e-12, 8.293975749251725e-12, 8.289214800671907e-12, 8.286133064416834e-12, 8.28131400260057e-12, 8.275802786117392e-12, 8.274366435079283e-12, 8.261403713905047e-12, 8.25398603632177e-12, 8.24759618239801e-12, 8.247439189923433e-12, 8.240960865102398e-12, 8.225602490807837e-12, 8.213718767635658e-12, 8.212183537359419e-12, 8.169408725888783e-12, 8.16433032291286e-12, 8.16193293506906e-12, 8.152815228479326e-12, 8.147452330853344e-12, 8.131213584394725e-12, 8.120193753513583e-12, 8.11390798299838e-12, 8.110396035321266e-12, 8.108508656179403e-12, 8.092733948250608e-12, 8.084032575295108e-12, 8.077019955643472e-12, 8.073108154205144e-12, 8.056971756431608e-12, 8.051809219367101e-12, 8.04827818973175e-12, 8.038398072174324e-12, 8.03360069440151e-12, 8.030261351710255e-12, 8.02366246360764e-12, 8.018613550930809e-12, 8.015677531447718e-12, 7.990719197437102e-12, 7.971705760778658e-12, 7.946733548980234e-12, 7.929881577772857e-12, 7.919345734741512e-12, 7.902265647397044e-12, 7.893317943707956e-12, 7.852458266954798e-12, 7.845242684656473e-12, 7.828053309733018e-12, 7.813658574329363e-12, 7.792078614288211e-12, 7.774382700109772e-12, 7.766201744197065e-12, 7.741518363857391e-12, 7.724600473157928e-12, 7.723303767359635e-12, 7.712146025962152e-12, 7.693839489120169e-12, 7.692240074075318e-12, 7.68506872722563e-12, 7.678021413104474e-12, 7.677084662427447e-12, 7.670190871333915e-12, 7.667192401805689e-12, 7.647022771950507e-12, 7.639252945501607e-12, 7.62927828551474e-12, 7.621933466317454e-12, 7.621511928512792e-12, 7.617311295615714e-12, 7.616251379571892e-12, 7.61180701802644e-12, 7.607830164457763e-12, 7.607699192835327e-12, 7.60732275784104e-12, 7.605886406802931e-12, 7.597998619157664e-12, 7.591436160248044e-12, 7.58772992354162e-12, 7.583389645404726e-12, 7.577288622939715e-12, 7.575597267550638e-12, 7.5646095290538e-12, 7.56373002425148e-12, 7.559158160530544e-12, 7.557096441679345e-12, 7.5537527621794e-12, 7.551577418940525e-12, 7.549791521122007e-12, 7.543343553961801e-12, 7.543242940000194e-12, 7.541314794856646e-12, 7.53372451228751e-12, 7.51440749902077e-12, 7.505655819084467e-12, 7.474112474759043e-12, 7.466703470793146e-12, 7.463969546595006e-12, 7.458717671271486e-12, 7.456427836283197e-12, 7.45244664590583e-12, 7.45038579441637e-12, 7.449590423702634e-12, 7.443738334056427e-12, 7.43909708139645e-12, 7.436487189926844e-12, 7.427910717061614e-12, 7.421099325333191e-12, 7.413628738683897e-12, 7.406915358831867e-12, 7.397258153241104e-12, 7.352373050661942e-12, 7.352261160997742e-12, 7.350760625191022e-12, 7.311914962393473e-12, 7.267214174183634e-12, 7.258916124436299e-12, 7.244779862830564e-12, 7.24100857399379e-12, 7.217980553531067e-12, 7.216906759699437e-12, 7.213782956400072e-12, 7.206521837610502e-12, 7.2035806139569836e-12, 7.2008198015449665e-12, 7.1998444532705985e-12, 7.199363934867753e-12, 7.198471419639363e-12, 7.196920143170971e-12, 7.179918552063791e-12, 7.176673751801976e-12, 7.16179632959113e-12, 7.161167926011958e-12, 7.1601296940115855e-12, 7.159747621166002e-12, 7.148258113903738e-12, 7.129399934996394e-12, 7.128529537492323e-12, 7.114864686991185e-12, 7.114023346105336e-12, 7.112381430335324e-12, 7.112354542121446e-12, 7.1111337304752276e-12, 7.098760815282823e-12, 7.0940913733663624e-12, 7.045640980363199e-12, 7.0429270054850335e-12, 7.021894784381422e-12, 7.019939751023996e-12, 7.019029454879977e-12, 7.0164460179433785e-12, 7.011549327251565e-12, 7.004358464762772e-12, 7.003329773741518e-12, 6.990131130174548e-12, 6.9887715406502515e-12, 6.981949740580973e-12, 6.961949679945567e-12, 6.930999177368058e-12, 6.925594646378652e-12, 6.923362490945939e-12, 6.921817719690582e-12, 6.919072086108979e-12, 6.914903111915338e-12, 6.89502925241281e-12, 6.893911656813412e-12, 6.893674867058941e-12, 6.8925837259925515e-12, 6.8904933842039995e-12, 6.889547526228723e-12, 6.872420167669535e-12, 6.871450023565595e-12, 6.859389792279735e-12, 6.8571398559313934e-12, 6.856263820576025e-12, 6.837354033645271e-12, 6.823661427568517e-12, 6.820798700152286e-12, 6.818431236288447e-12, 6.8049324855601334e-12, 6.804750339595156e-12, 6.79979423462429e-12, 6.792081654050097e-12, 6.784455809649703e-12, 6.783433623841484e-12, 6.775429176042458e-12, 6.772922500619671e-12, 6.750597910526457e-12, 6.734804988001164e-12, 6.734291076171406e-12, 6.704711005139918e-12, 6.704468143853282e-12, 6.694934970991051e-12, 6.6946795329592135e-12, 6.685071333306647e-12, 6.684676250034993e-12, 6.6800879064410346e-12, 6.6765083045483564e-12, 6.675502598613159e-12, 6.664027836500441e-12, 6.652902621168133e-12, 6.643379422965889e-12, 6.639667982089037e-12, 6.638085046917208e-12, 6.637882517951388e-12, 6.629771818339458e-12, 6.611839981768286e-12, 6.588211313302006e-12, 6.573199450021772e-12, 6.570429096630637e-12, 6.558972115433548e-12, 6.5536200598292904e-12, 6.544763429122691e-12, 6.544364009042347e-12, 6.5414939090513435e-12, 6.5412692623612045e-12, 6.540869842280861e-12, 6.540283505745981e-12, 6.536667040979438e-12, 6.531059113662474e-12, 6.511419008148334e-12, 6.506576961246013e-12, 6.506167566505683e-12, 6.502358981114176e-12, 6.50069711602419e-12, 6.490958812110925e-12, 6.482570556742839e-12, 6.4733531035532366e-12, 6.469353698579372e-12, 6.464370705394629e-12, 6.449887065412829e-12, 6.435374368812807e-12, 6.430147646979689e-12, 6.426199850029235e-12, 6.424459488701961e-12, 6.4210780789664135e-12, 6.415581607632781e-12, 6.4139665800766466e-12, 6.397301525323806e-12, 6.3896678746677704e-12, 6.383784126318126e-12, 6.383248096764049e-12, 6.368011153112807e-12, 6.361201062426991e-12, 6.353210492415773e-12, 6.349963957430482e-12, 6.340535735338548e-12, 6.314816725083716e-12, 6.312757174636863e-12, 6.31146914245595e-12, 6.3058980780128504e-12, 6.303024074894026e-12, 6.301268968417206e-12, 6.28469281824251e-12, 6.271580910849339e-12, 6.268770658818257e-12, 6.263834503167365e-12, 6.242937590494879e-12, 6.2387118041074e-12, 6.237617193594058e-12, 6.236677407150948e-12, 6.234405786759156e-12, 6.22701369634715e-12, 6.216772322625852e-12, 6.213346243760798e-12, 6.200998048377926e-12, 6.19447245234217e-12, 6.188508906712631e-12, 6.1566741288432425e-12, 6.152870313941294e-12, 6.152048922375419e-12, 6.1505353761426296e-12, 6.148623710872103e-12, 6.146817863733611e-12, 6.14236439488991e-12, 6.14182532956975e-12, 6.140408060489877e-12, 6.133946649222732e-12, 6.131302930645344e-12, 6.11143123954716e-12, 6.106991648491267e-12, 6.105559200580979e-12, 6.102869511831477e-12, 6.1021478668654705e-12, 6.1020663348620996e-12, 6.1010307049469414e-12, 6.096854358178527e-12, 6.096493969376393e-12, 6.090380803847051e-12, 6.088267043291573e-12, 6.078242076323903e-12, 6.075680323430754e-12, 6.068661632246952e-12, 6.06704140052039e-12, 6.06216032233986e-12, 6.059720867451768e-12, 6.044057181825435e-12, 6.0438034785170736e-12, 6.0411181265762615e-12, 6.039873896163117e-12, 6.039827925991004e-12, 6.035106442370264e-12, 6.033794124060687e-12, 6.032850434489756e-12, 6.028111603634256e-12, 6.022928249888038e-12, 6.006763662858017e-12, 5.9994470329172156e-12, 5.998223185504914e-12, 5.978930458366838e-12, 5.978896631259056e-12, 5.975088913229287e-12, 5.966149015795841e-12, 5.966137740093247e-12, 5.957529608524581e-12, 5.954973493482729e-12, 5.927324169680004e-12, 5.921922240775812e-12, 5.9115624721772786e-12, 5.901794677964922e-12, 5.899802781733632e-12, 5.8929423840670125e-12, 5.889391838792557e-12, 5.855810628063729e-12, 5.854359098195205e-12, 5.846670370068807e-12, 5.846525520658563e-12, 5.840941445789394e-12, 5.824498435641479e-12, 5.819678940144346e-12, 5.8154622610551154e-12, 5.802355557832373e-12, 5.799201830553047e-12, 5.793110349067154e-12, 5.779579505954535e-12, 5.777452734972988e-12, 5.777353422053988e-12, 5.775832936927294e-12, 5.775172007282947e-12, 5.773288531268905e-12, 5.7606389276820824e-12, 5.760210450983516e-12, 5.758903336844368e-12, 5.757135219941478e-12, 5.753808887676293e-12, 5.748609487737921e-12, 5.734657540501509e-12, 5.730590047631212e-12, 5.720357347527294e-12, 5.719386336061616e-12, 5.718830357187565e-12, 5.717521508324941e-12, 5.7167252702494675e-12, 5.702644086114095e-12, 5.702317524419742e-12, 5.694166492486996e-12, 5.6927982293453194e-12, 5.690583421147366e-12, 5.688130955833204e-12, 5.661655606142846e-12, 5.6542739240716955e-12, 5.6517295184133065e-12, 5.651459768912792e-12, 5.646385269064691e-12, 5.6422297389779885e-12, 5.642067976013854e-12, 5.636593188723671e-12, 5.630372036657949e-12, 5.622216234235644e-12, 5.612359101764275e-12, 5.603823394900731e-12, 5.594083789944859e-12, 5.592163451056953e-12, 5.585799617985332e-12, 5.55864469037326e-12, 5.544159749348854e-12, 5.5414002379794436e-12, 5.536033870906509e-12, 5.521702452909727e-12, 5.520849402640415e-12, 5.513756552028015e-12, 5.513346289925947e-12, 5.513325473244235e-12, 5.5116323831316816e-12, 5.5061268044998e-12, 5.500951690690092e-12, 5.4989272683936274e-12, 5.49581300607338e-12, 5.495750122347376e-12, 5.492585119365456e-12, 5.484179516762611e-12, 5.4821711406582985e-12, 5.479076827658025e-12, 5.477196387410066e-12, 5.471078017710296e-12, 5.467249482998815e-12, 5.459975353783175e-12, 5.459850453692905e-12, 5.4559677088728e-12, 5.4494781083491706e-12, 5.44831410889679e-12, 5.446911151285594e-12, 5.4442418455369346e-12, 5.440971891784718e-12, 5.425365452033093e-12, 5.420121382965215e-12, 5.419924491850692e-12, 5.415657072099789e-12, 5.41369466616759e-12, 5.412187625147835e-12, 5.4079774512716394e-12, 5.403059510217245e-12, 5.396241179594918e-12, 5.377879998963442e-12, 5.365984132726931e-12, 5.3589775846074605e-12, 5.354676337748776e-12, 5.350837394696439e-12, 5.350337794335358e-12, 5.3483580411683995e-12, 5.344197740592138e-12, 5.343025501203247e-12, 5.341741372150155e-12, 5.339062959103247e-12, 5.339052550762391e-12, 5.33451277942576e-12, 5.3262164644019006e-12, 5.325444512455091e-12, 5.31250954685647e-12, 5.310786966444825e-12, 5.299979639189489e-12, 5.297635160411707e-12, 5.290344985003914e-12, 5.287500038503312e-12, 5.287308351559217e-12, 5.280948855296286e-12, 5.277998090663649e-12, 5.269850094496986e-12, 5.265519791020079e-12, 5.2640639243428655e-12, 5.2634715162758194e-12, 5.262698696967272e-12, 5.262527826704888e-12, 5.2610723937085435e-12, 5.259256571910065e-12, 5.25532612219437e-12, 5.238133277823964e-12, 5.226546626047046e-12, 5.2254697964493335e-12, 5.223885560234898e-12, 5.213225250794151e-12, 5.206309341976301e-12, 5.20286461483388e-12, 5.184449224093779e-12, 5.180772044005577e-12, 5.17862792578927e-12, 5.175478101637765e-12, 5.174737808394392e-12, 5.174323209483633e-12, 5.170969121642832e-12, 5.169203606825157e-12, 5.1669757882011336e-12, 5.164552379505194e-12, 5.158723708625912e-12, 5.149610338844868e-12, 5.146576307485384e-12, 5.137073492283983e-12, 5.133087097736189e-12, 5.130737848468847e-12, 5.1149184714105456e-12, 5.113737992085143e-12, 5.093869336753043e-12, 5.089480052677953e-12, 5.089169103494884e-12, 5.087073123855035e-12, 5.081894540598375e-12, 5.078909948857957e-12, 5.076140029147691e-12, 5.047658471757366e-12, 5.044847786045414e-12, 5.042010212119585e-12, 5.03754980438198e-12, 5.034121123431712e-12, 5.032028179557946e-12, 5.030013298240599e-12, 5.022966417800312e-12, 5.019834374564436e-12, 5.014275019504799e-12, 5.010297732255253e-12, 5.0010078543605285e-12, 4.996546145580316e-12, 4.990573926333397e-12, 4.988689582957617e-12, 4.9735549879914576e-12, 4.9722838693644356e-12, 4.9718384791119785e-12, 4.970662336595266e-12, 4.96978109706947e-12, 4.96921210776935e-12, 4.964011406788371e-12, 4.9601689942890825e-12, 4.958248655401176e-12, 4.9576341296098114e-12, 4.946998106297729e-12, 4.9369783435004866e-12, 4.9336927772369865e-12, 4.9256913652040435e-12, 4.915770481644932e-12, 4.909670760222529e-12, 4.908369283934677e-12, 4.906226033080108e-12, 4.904410644962498e-12, 4.900922983414047e-12, 4.899772861749474e-12, 4.899193464108498e-12, 4.894523588511168e-12, 4.892535595407699e-12, 4.891593206879374e-12, 4.879199908686127e-12, 4.877953076187769e-12, 4.8773762806320065e-12, 4.862347503797881e-12, 4.852230596485985e-12, 4.842153154133166e-12, 4.842005702637708e-12, 4.830972427649627e-12, 4.8292038770658685e-12, 4.821638314306265e-12, 4.8205254891964255e-12, 4.804718688883325e-12, 4.804389091422889e-12, 4.804343121250776e-12, 4.7951790108080594e-12, 4.794227948662355e-12, 4.791549535615447e-12, 4.789804403798614e-12, 4.781388392854913e-12, 4.77556449246519e-12, 4.7724411228466934e-12, 4.75219429779683e-12, 4.742985084543738e-12, 4.7363042307568826e-12, 4.731545884262278e-12, 4.730057057839021e-12, 4.729100791522889e-12, 4.725043706993448e-12, 4.724160299063307e-12, 4.72220569938675e-12, 4.721098078447339e-12, 4.719081028725647e-12, 4.7167864232477985e-12, 4.7162647051623985e-12, 4.708974963435475e-12, 4.7022702572008246e-12, 4.6959966297499545e-12, 4.6764753527939185e-12, 4.6705651499112655e-12, 4.657150533271537e-12, 4.65516991274284e-12, 4.65120303383415e-12, 4.6342890462625075e-12, 4.633493675548772e-12, 4.62249509503021e-12, 4.61344027216648e-12, 4.612270201181934e-12, 4.6069068698750826e-12, 4.606221654102072e-12, 4.579555484829356e-12, 4.575164032349921e-12, 4.5717618059326615e-12, 4.565809969686585e-12, 4.5641992789391406e-12, 4.554789705124573e-12, 4.554607125478727e-12, 4.5434845122316325e-12, 4.541274908204107e-12, 4.5398979714450505e-12, 4.53888489293508e-12, 4.532180620381299e-12, 4.531082974101874e-12, 4.530719983214526e-12, 4.529397690244963e-12, 4.5249424866777854e-12, 4.5245625822365465e-12, 4.524398650868067e-12, 4.516268435617032e-12, 4.513917017945346e-12, 4.511386490074765e-12, 4.507069197023927e-12, 4.500694955611451e-12, 4.477209401831939e-12, 4.475006736698317e-12, 4.474733517750851e-12, 4.4695133011307675e-12, 4.469470800405606e-12, 4.465184732377336e-12, 4.459252411770365e-12, 4.456531931679164e-12, 4.454891316951759e-12, 4.453863493292243e-12, 4.453005672533372e-12, 4.4493974477033404e-12, 4.444045392099083e-12, 4.441223864365407e-12, 4.438801756712074e-12, 4.4328876507016e-12, 4.432135214393895e-12, 4.4253775990932276e-12, 4.414603231583936e-12, 4.406880242668887e-12, 4.3918015925348275e-12, 4.384336210055961e-12, 4.383115398409743e-12, 4.368892834311078e-12, 4.3651779239872734e-12, 4.365061263833514e-12, 4.350764540306251e-12, 4.341935665175267e-12, 4.336167275936775e-12, 4.325964933493687e-12, 4.314733466348475e-12, 4.313392091420676e-12, 4.310924880956968e-12, 4.308006642389506e-12, 4.304786995618093e-12, 4.3002489590049375e-12, 4.298174229727669e-12, 4.294208218180717e-12, 4.293307463015816e-12, 4.286540306736031e-12, 4.282576897274293e-12, 4.2810334270615424e-12, 4.280813117180093e-12, 4.275932906361302e-12, 4.2734709000680215e-12, 4.269046921523412e-12, 4.268721227190797e-12, 4.259466043765592e-12, 4.2573865439987646e-12, 4.256444589151309e-12, 4.253247060104215e-12, 4.243046018703733e-12, 4.238710077375529e-12, 4.226294227777094e-12, 4.224343964909227e-12, 4.2235138997259725e-12, 4.2211143434778275e-12, 4.2148389813034814e-12, 4.209407995781067e-12, 4.208813852990545e-12, 4.207240892478703e-12, 4.201531050157525e-12, 4.2001046737794034e-12, 4.190502545659003e-12, 4.185701698439237e-12, 4.183802176233042e-12, 4.181959032539817e-12, 4.1723503992063815e-12, 4.166640556885204e-12, 4.158867260989352e-12, 4.151069245283967e-12, 4.148354403044063e-12, 4.1463924307927336e-12, 4.138941359782544e-12, 4.136889615591333e-12, 4.1332375889935324e-12, 4.132512474580574e-12, 4.1321182586706584e-12, 4.11957447321587e-12, 4.1155772366463506e-12, 4.1147528093143926e-12, 4.112555782032068e-12, 4.112171540782139e-12, 4.11213250950393e-12, 4.102989649423794e-12, 4.099969929532987e-12, 4.098984606598632e-12, 4.098507991323608e-12, 4.096413312726366e-12, 4.0952337007627015e-12, 4.077424162196586e-12, 4.073203579979534e-12, 4.070205977813046e-12, 4.060218741080979e-12, 4.05655760718493e-12, 4.056379364347773e-12, 4.055613483933129e-12, 4.045245909078954e-12, 4.036290399134224e-12, 4.0356203621916276e-12, 4.028768204461519e-12, 4.024267464403097e-12, 4.020945468946602e-12, 4.020186093744993e-12, 4.020155302403294e-12, 4.013880373909817e-12, 4.010979916257984e-12, 4.000001285059396e-12, 3.996973758912947e-12, 3.994275830226934e-12, 3.993864267082259e-12, 3.988398587090325e-12, 3.987790132831126e-12, 3.985980382564813e-12, 3.983677537150454e-12, 3.982628896809226e-12, 3.975699543884437e-12, 3.974410644341786e-12, 3.967442693819656e-12, 3.964144550810955e-12, 3.960214968456999e-12, 3.9553685847459885e-12, 3.952834587428455e-12, 3.951568239290992e-12, 3.947989504760052e-12, 3.945731328475199e-12, 3.927567906319984e-12, 3.914659395254372e-12, 3.901956882601532e-12, 3.892338274608109e-12, 3.8907497015849835e-12, 3.8891693684983686e-12, 3.881151476592404e-12, 3.881144104017631e-12, 3.8720420099391806e-12, 3.8719019310184954e-12, 3.8717466732673955e-12, 3.8715176897685666e-12, 3.8701004206886935e-12, 3.8594114883105934e-12, 3.854813603737517e-12, 3.8519326617247884e-12, 3.84978030357197e-12, 3.845905365007507e-12, 3.8439984702265395e-12, 3.8401074854699235e-12, 3.838525851340702e-12, 3.834376826467034e-12, 3.8263476588584755e-12, 3.8221535311744326e-12, 3.821912838292141e-12, 3.818029226110298e-12, 3.816864359296179e-12, 3.815554209390948e-12, 3.814477379793235e-12, 3.813204092761868e-12, 3.8074265962251275e-12, 3.806126854660752e-12, 3.803434563826036e-12, 3.801679457349216e-12, 3.782180298117499e-12, 3.781834220784042e-12, 3.7761543024428246e-12, 3.773037004356494e-12, 3.771706037769551e-12, 3.771432385141216e-12, 3.766867460314183e-12, 3.7644110918721996e-12, 3.7622504937828705e-12, 3.755282109579872e-12, 3.7508724425039386e-12, 3.7496134669412484e-12, 3.7202064345764896e-12, 3.714428070678011e-12, 3.710356674679893e-12, 3.7083261808512624e-12, 3.704939566945287e-12, 3.702671849681316e-12, 3.6976259727705685e-12, 3.697407397612595e-12, 3.694291400568872e-12, 3.694101014667384e-12, 3.69274879771786e-12, 3.681833483926145e-12, 3.681180360537439e-12, 3.669837437408896e-12, 3.663990551933116e-12, 3.6597717044395406e-12, 3.656813133551262e-12, 3.647896654884741e-12, 3.642522047875296e-12, 3.639563476987018e-12, 3.633972680064379e-12, 3.6309171815018804e-12, 3.6303633710321748e-12, 3.6261072269838657e-12, 3.6246689243818464e-12, 3.6219046425228774e-12, 3.6082176742974204e-12, 3.6015619740009663e-12, 3.598286816078322e-12, 3.5928551800346042e-12, 3.5889581237458223e-12, 3.5752319074017214e-12, 3.5714016379667646e-12, 3.5554497714029853e-12, 3.551816826763421e-12, 3.5339027711078774e-12, 3.531362485417744e-12, 3.530534154957965e-12, 3.5276330467848283e-12, 3.5066157876711967e-12, 3.504676583665489e-12, 3.502190941764849e-12, 3.500347581231189e-12, 3.4990727763167806e-12, 3.4940240804803846e-12, 3.4899080153527606e-12, 3.4832911294940816e-12, 3.462742679399833e-12, 3.459178039497135e-12, 3.4587293966381605e-12, 3.453778712678157e-12, 3.453389917779104e-12, 3.4522770926692647e-12, 3.4459221500554582e-12, 3.438247299716868e-12, 3.4343279088633327e-12, 3.4334763764770626e-12, 3.420044846283443e-12, 3.4183166280205013e-12, 3.40435991029453e-12, 3.401906360778195e-12, 3.3935335010809586e-12, 3.389891232302711e-12, 3.384729128919073e-12, 3.3748596365429373e-12, 3.373868458916851e-12, 3.3737719649235e-12, 3.3705560044394733e-12, 3.3692447703320694e-12, 3.367901877521229e-12, 3.3667138087806192e-12, 3.3601253290188593e-12, 3.3523028103443764e-12, 3.3522195436175295e-12, 3.3512350880449127e-12, 3.347925669333618e-12, 3.3301759787274232e-12, 3.3269953632342197e-12, 3.3250542076646017e-12, 3.324236068705244e-12, 3.3236590563090473e-12, 3.320205872389681e-12, 3.3177939562367698e-12, 3.3177560091607328e-12, 3.304323394764941e-12, 3.3029622873576026e-12, 3.3004434688704842e-12, 3.2972155821625604e-12, 3.2970646612201504e-12, 3.282294358183946e-12, 3.2774273746316585e-12, 3.2698158416999412e-12, 3.268562503988548e-12, 3.262763540248792e-12, 3.2589324034520972e-12, 3.257142602505758e-12, 3.253113273551933e-12, 3.2530699054650336e-12, 3.2490702836507346e-12, 3.2422172585588882e-12, 3.2393614700365614e-12, 3.238354463058757e-12, 3.2358107079216714e-12, 3.2330592196483376e-12, 3.231918638962883e-12, 3.229392231060557e-12, 3.224505298188296e-12, 3.2142752001695918e-12, 3.2102558458757535e-12, 3.2085480106136544e-12, 3.2064986516672223e-12, 3.2043710133239367e-12, 3.2035337924063434e-12, 3.199759901484356e-12, 3.191677391128911e-12, 3.1815758794878635e-12, 3.1794345801972046e-12, 3.168936467401462e-12, 3.1629523219306455e-12, 3.1578043131752498e-12, 3.154246612166456e-12, 3.152129815844895e-12, 3.1453132199460443e-12, 3.1425847167587673e-12, 3.1396072807526876e-12, 3.1326384628688198e-12, 3.126675134079715e-12, 3.120758859664896e-12, 3.1202529709312143e-12, 3.109428296441119e-12, 3.1092504872848314e-12, 3.1089538495704394e-12, 3.103556474315372e-12, 3.1010357042643433e-12, 3.0976720754444242e-12, 3.094129119585176e-12, 3.0906256286850065e-12, 3.09050766748864e-12, 3.0883214822280403e-12, 3.08829784662068e-12, 3.0861133960835563e-12, 3.0798037731205596e-12, 3.071432648146799e-12, 3.0703666605708113e-12, 3.0623422634518116e-12, 3.06009427866738e-12, 3.057031624370543e-12, 3.0453688616011165e-12, 3.042616939646914e-12, 3.0343004584626465e-12, 3.0263129242175113e-12, 3.0247950411760316e-12, 3.0247894033247347e-12, 3.0205401981703295e-12, 3.015601223593789e-12, 3.015497790706534e-12, 3.011296290447718e-12, 3.0086265510181898e-12, 3.0054778110688574e-12, 3.001496403851056e-12, 2.9969084939379664e-12, 2.9945657498836598e-12, 2.992458928222086e-12, 2.991631465124045e-12, 2.99143739293517e-12, 2.9906786682548647e-12, 2.9889393911297635e-12, 2.9828511622503884e-12, 2.980099023455751e-12, 2.9797807016979094e-12, 2.9681012422150266e-12, 2.944969572024614e-12, 2.943240052719065e-12, 2.9368976868504593e-12, 2.9268096193163506e-12, 2.923757590200804e-12, 2.922436381433413e-12, 2.918208643482023e-12, 2.9089170308638224e-12, 2.908844822999135e-12, 2.8946098989957036e-12, 2.8944552917659072e-12, 2.8940135878008366e-12, 2.8937431877790187e-12, 2.888647871249206e-12, 2.8840068354296644e-12, 2.8801644229303758e-12, 2.869264071128641e-12, 2.8639768508142982e-12, 2.8627315361989814e-12, 2.858023279844746e-12, 2.8481138888286628e-12, 2.8473913765009184e-12, 2.8426215374632857e-12, 2.8416078084320118e-12, 2.837399802960161e-12, 2.836663846525478e-12, 2.8346680471663666e-12, 2.825060281194669e-12, 2.8228411361880257e-12, 2.8195104671141502e-12, 2.8136440659992656e-12, 2.8043483334128094e-12, 2.7962619199295435e-12, 2.7957284924606807e-12, 2.792722650357682e-12, 2.786247578143164e-12, 2.782269857212749e-12, 2.7810284457252532e-12, 2.778562969985021e-12, 2.7781390469355793e-12, 2.777328497391429e-12, 2.7730198779579718e-12, 2.7615871828895466e-12, 2.7492524316136135e-12, 2.7489902715283066e-12, 2.7480361736165193e-12, 2.744699433010478e-12, 2.74375205715216e-12, 2.7412254324094e-12, 2.7356261787098157e-12, 2.73345126915181e-12, 2.732846718020432e-12, 2.72973657566844e-12, 2.722181854930561e-12, 2.7213355267147188e-12, 2.710136802475116e-12, 2.700606014857665e-12, 2.6888771157557168e-12, 2.681793589282e-12, 2.681292471037877e-12, 2.6802082688653917e-12, 2.677413629345593e-12, 2.6744685025642534e-12, 2.6712414832180675e-12, 2.6632491784833734e-12, 2.652572822850474e-12, 2.6445354153054046e-12, 2.642629387886175e-12, 2.6417828428298984e-12, 2.6415712065658292e-12, 2.635632597586257e-12, 2.6319604048280487e-12, 2.6317294697653093e-12, 2.6174672238671315e-12, 2.6053985358043263e-12, 2.6028257240490182e-12, 2.6008702570107234e-12, 2.5941425656900163e-12, 2.588226508115632e-12, 2.5850985848480112e-12, 2.581516380870119e-12, 2.5777672097576643e-12, 2.575830824677605e-12, 2.5749415620557325e-12, 2.5720896766612267e-12, 2.56858922152714e-12, 2.562291741628475e-12, 2.5586045868802865e-12, 2.5548885923543097e-12, 2.551606278697327e-12, 2.5471619171518745e-12, 2.5400883653381445e-12, 2.539235748749702e-12, 2.5361379663024763e-12, 2.5243865157953405e-12, 2.5162673594064655e-12, 2.5111130622784694e-12, 2.5110126651572973e-12, 2.5024351080898954e-12, 2.4994823918933484e-12, 2.498724534574781e-12, 2.498590960867131e-12, 2.4952286330898188e-12, 2.4941485508855887e-12, 2.49259358812981e-12, 2.4868427629665124e-12, 2.484993547741121e-12, 2.479468453470135e-12, 2.4779885175046923e-12, 2.4706074859548455e-12, 2.457598144087192e-12, 2.4572232269759464e-12, 2.4505395542634423e-12, 2.449843279628272e-12, 2.4455856176969215e-12, 2.4412514110921935e-12, 2.4346716049478134e-12, 2.4345647026136064e-12, 2.4324387989937968e-12, 2.4269102352758587e-12, 2.422317988554079e-12, 2.4223086644153957e-12, 2.419293715014148e-12, 2.4183478570388717e-12, 2.416757115611401e-12, 2.4142461033799245e-12, 2.4136615015685203e-12, 2.3861284042386854e-12, 2.385027288512309e-12, 2.38243127483051e-12, 2.3694568442728103e-12, 2.3580952728669002e-12, 2.3417624176597096e-12, 2.339931850711685e-12, 2.3375630858052387e-12, 2.3196596553309856e-12, 2.319146394022531e-12, 2.3168695694603114e-12, 2.3107351535683884e-12, 2.309109283990529e-12, 2.3076829076124072e-12, 2.3040323988976485e-12, 2.2853218883261972e-12, 2.2797232851479166e-12, 2.275882607372104e-12, 2.2742033950473584e-12, 2.2735138424656576e-12, 2.269242302746499e-12, 2.2562559459649023e-12, 2.2528587068776362e-12, 2.249737071982616e-12, 2.2493294119657614e-12, 2.237092672566221e-12, 2.2295954145434838e-12, 2.224909709594436e-12, 2.223967971587415e-12, 2.1957448879950103e-12, 2.194827869797522e-12, 2.188966456012631e-12, 2.1810522138343558e-12, 2.1794345841930074e-12, 2.1717827189404737e-12, 2.1686036213303117e-12, 2.1654995505104857e-12, 2.160684825502912e-12, 2.159749592708926e-12, 2.1571188845576073e-12, 2.1567485210954862e-12, 2.149779052690315e-12, 2.1435021726329273e-12, 2.1403972344513633e-12, 2.1397482310309135e-12, 2.138597675685472e-12, 2.1370318709079683e-12, 2.1199726002452124e-12, 2.1177256996629534e-12, 2.112593953940145e-12, 2.1103023842283797e-12, 2.1071250213416937e-12, 2.099706910077548e-12, 2.093995766713763e-12, 2.087770494679786e-12, 2.0833907515838135e-12, 2.0646084668285436e-12, 2.06447857940828e-12, 2.0493114583769456e-12, 2.049014603822119e-12, 2.0405745235901884e-12, 2.038699504353092e-12, 2.032840258972546e-12, 2.032514564639931e-12, 2.0284635516426563e-12, 2.0174359145058718e-12, 2.0108053676998194e-12, 2.0000797892882893e-12, 1.994293402293734e-12, 1.9879928866289864e-12, 1.981209684157048e-12, 1.9811379099732296e-12, 1.9639890842110264e-12, 1.9618063683973785e-12, 1.9560225834880374e-12, 1.943434345744177e-12, 1.9342669826949432e-12, 1.9187860935548917e-12, 1.9108169907466888e-12, 1.884633074600295e-12, 1.883371713792825e-12, 1.878445966482789e-12, 1.8747950240871614e-12, 1.8746306590378126e-12, 1.870737289036417e-12, 1.865556320534978e-12, 1.8641479419129192e-12, 1.8486991451571733e-12, 1.8444620830671e-12, 1.8416323153969127e-12, 1.8408386794066534e-12, 1.8385262930131763e-12, 1.836714157502084e-12, 1.8198120961543385e-12, 1.794995033686797e-12, 1.7949026596617013e-12, 1.7938964116254175e-12, 1.7849780898152035e-12, 1.767193162638403e-12, 1.7646131951487565e-12, 1.7627831703018182e-12, 1.7457854823224594e-12, 1.7402003232511176e-12, 1.726134426366377e-12, 1.7218235301083573e-12, 1.7122441702335789e-12, 1.7109579811963593e-12, 1.710514217247161e-12, 1.6986991240725002e-12, 1.6984269893272064e-12, 1.6928641648206177e-12, 1.6852417898671757e-12, 1.6819279259269737e-12, 1.665427127803265e-12, 1.6629861550321312e-12, 1.6570525333825525e-12, 1.6567176233314718e-12, 1.6439973297630028e-12, 1.6369727838874693e-12, 1.6352970410096757e-12, 1.6288749862813923e-12, 1.6198839145054045e-12, 1.6154592854394911e-12, 1.6126209525721413e-12, 1.6075169624249486e-12, 1.5996960700537244e-12, 1.5886071754941944e-12, 1.5881344633469907e-12, 1.5741954181164308e-12, 1.5714505434763493e-12, 1.5663573953508814e-12, 1.5663364702489524e-12, 1.558302640571052e-12, 1.5569152954711396e-12, 1.5502066861086683e-12, 1.5498636445412939e-12, 1.537887547344019e-12, 1.515891253668633e-12, 1.5109696263268524e-12, 1.5044072758374494e-12, 1.5020877337096339e-12, 1.4876974435348855e-12, 1.4819313311209559e-12, 1.4583940608978163e-12, 1.4369344472978107e-12, 1.4352662938352245e-12, 1.420949620987988e-12, 1.4171657554060135e-12, 1.4110593119301407e-12, 1.3977409724433287e-12, 1.3935324248703918e-12, 1.37976880355134e-12, 1.3636341405012797e-12, 1.35512467133031e-12, 1.350632171208399e-12, 1.3282325543248485e-12, 1.3055143988430218e-12, 1.302919903044264e-12, 1.3020727074666838e-12, 1.2937621893943652e-12, 1.27739247131331e-12, 1.2494831558296227e-12, 1.2178948171140402e-12, 1.2004364516315924e-12, 1.1895235230846568e-12, 1.156694423402882e-12, 1.148415564034e-12, 1.1467564094494453e-12, 1.1026860848029063e-12, 1.1020552959789542e-12, 1.1006835633903256e-12, 1.0798701342851214e-12, 1.0579014877651338e-12, 1.0487401962480658e-12, 1.0285342456201052e-12, 1.0181678633883195e-12, 8.380572711491618e-13, 8.364986221059967e-13, 8.001344812408329e-13, 7.794913802969261e-13, 6.89743292862921e-13, 6.892159369262241e-13, 6.512607835830464e-13, 6.467154828153354e-13, 6.034941968900698e-13, 5.915833686635785e-13, 5.540023734901256e-13, 5.51403811933221e-13, 5.111480290138741e-14]\n",
            "[0, 9, 1, 0, 344, 889, 7, 0, 128, 116, 38, 858, 69, 7, 580, 6, 723, 42, 399, 118, 1281, 230, 83, 213, 289, 188, 70, 326, 819, 1243, 6, 1026, 270, 46, 1266, 129, 43, 546, 708, 27, 204, 1145, 588, 1001, 223, 523, 0, 726, 366, 97, 15, 1760, 841, 13, 1335, 668, 1523, 1033, 700, 695, 1065, 1521, 812, 343, 1737, 991, 1294, 383, 1101, 808, 510, 1103, 385, 1560, 1504, 1001, 1391, 52, 27, 541, 196, 529, 1625, 407, 158, 340, 1779, 226, 673, 54, 0, 19, 0, 25, 426, 7, 0, 24, 8, 1078, 1382, 0, 48, 72, 0, 153, 1000, 221, 114, 378, 1732, 73, 1620, 0, 10, 137, 181, 172, 45, 1557, 522, 1127, 314, 443, 458, 69, 324, 985]\n"
          ]
        }
      ]
    }
  ]
}